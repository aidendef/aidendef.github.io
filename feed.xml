<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://aidendef.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://aidendef.github.io//" rel="alternate" type="text/html" /><updated>2025-05-27T07:12:48+00:00</updated><id>https://aidendef.github.io//feed.xml</id><title type="html">Aiden의 든든한 Blog</title><subtitle>Aiden&apos;s website.</subtitle><author><name>Your Name</name></author><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(8)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(8)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(8)" /><published>2025-05-26T15:08:00+00:00</published><updated>2025-05-26T15:08:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(8)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(8)/"><![CDATA[<h2 id="동적인-breakpoint">동적인 Breakpoint</h2>

<p>특정 단계에서 그래프를 멈추는 일반적인 방법으로 중단점을 다루었으며, 이를 통해 ‘승인’과 같은 사용 사례를 구현할 수 있습니다.</p>

<p>또한 그래프 상태를 편집하는 방법과 사람의 피드백을 도입하는 방법도 소개했습니다.</p>

<p>중단점은 개발자가 그래프를 컴파일하는 동안 특정 노드에 설정합니다.</p>

<p>하지만 때로는 그래프가 동적으로 중단되도록 하는 것이 유용할 때가 있습니다!</p>

<p>이것은 내부 중단점이며, NodeInterrupt를 사용하여 달성할 수 있습니다.</p>

<p>여기에는 몇 가지 구체적인 이점이 있습니다:</p>

<p>(1) 개발자가 정의한 로직에 따라 노드 내부에서 조건부로 수행할 수 있습니다.</p>

<p>(2) 사용자에게 인터럽트 이유를 전달할 수 있습니다(원하는 내용을 NodeInterrupt에 전달하여).</p>

<p>그러면, 다음 예제를 통해서 입력의 길이에 따라 NodeInterrupt가 발생하는 그래프를 만들어 보겠습니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display

from typing_extensions import TypedDict
from langgraph.checkpoint.memory import MemorySaver
from langgraph.errors import NodeInterrupt
from langgraph.graph import START, END, StateGraph

class State(TypedDict):
    input: str

def step_1(state: State) -&gt; State:
    print("---Step 1---")
    return state

def step_2(state: State) -&gt; State:
    # Let's optionally raise a NodeInterrupt if the length of the input is longer than 5 characters
    print("--Step 2 (before Node Interrupt)--")
    if len(state['input']) &gt; 5:
        raise NodeInterrupt(f"Received input that is longer than 5 characters: {state['input']}")
    
    print("---Step 2---")
    return state

def step_3(state: State) -&gt; State:
    print("---Step 3---")
    return state

builder = StateGraph(State)
builder.add_node("step_1", step_1)
builder.add_node("step_2", step_2)
builder.add_node("step_3", step_3)
builder.add_edge(START, "step_1")
builder.add_edge("step_1", "step_2")
builder.add_edge("step_2", "step_3")
builder.add_edge("step_3", END)

# Set up memory
memory = MemorySaver()

# Compile the graph with memory
graph = builder.compile(checkpointer=memory)

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>

<p><img src="/assets/images/post_img/langgraph8.png" alt="langgraph8" /></p>

<p>5자보다 긴 글자 입력으로 그래프를 실행해 보겠습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>initial_input = {"input": "hello world"}
thread_config = {"configurable": {"thread_id": "1"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread_config, stream_mode="values"):
    print(event)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'input': 'hello world'}
---Step 1---
{'input': 'hello world'}
--Step 2 (before Node Interrupt)--
</code></pre></div></div>
<p>이 시점에서 그래프 상태를 검사하면, step_2가 다음 노드라고 가리키고 있음을 알 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread_config)
print(state.next)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('step_2',)
</code></pre></div></div>
<p>상세내용을 확인해 보면, <code class="language-plaintext highlighter-rouge">Interrupt</code>가 상태로 기록된 것을 볼 수 있습니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(state.tasks)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(PregelTask(id='39005008-94cd-c3f2-e40e-638b2445966a', name='step_2', path=('__pregel_pull', 'step_2'), error=None, interrupts=(Interrupt(value='Received input that is longer than 5 characters: hello world', resumable=False, ns=None, when='during'),), state=None, result=None),)
</code></pre></div></div>
<p>중단점에서 그래프를 다시 시작할 수 있습니다.</p>

<p>하지만 이것은 동일한 노드를 다시 실행할 뿐입니다!</p>

<p>상태가 변경되지 않는 한 우리는 여기서 멈출 것입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread_config, stream_mode="values"):
    print(event)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'input': 'hello world'}
--Step 2 (before Node Interrupt)--
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread_config)
print(state.next)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('step_2',)
</code></pre></div></div>

<p>그래서 우리는 상태를 업데이트해서 이 상태를 벗어나게 할 것입니다.
이번에는 5자보다 적은 글자수를 입력하여 수행해 보입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.update_state(
    thread_config,
    {"input": "hi"},
)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'configurable': {'thread_id': '1',
  'checkpoint_ns': '',
  'checkpoint_id': '1eff4f97-39ca-67f8-8002-98b845337fa1'}}
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread_config, stream_mode="values"):
    print(event)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'input': 'hi'}
--Step 2 (before Node Interrupt)--
---Step 2---
{'input': 'hi'}
---Step 3---
{'input': 'hi'}
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread_config)
print(state.next)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>()
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[동적인 Breakpoint을 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(7)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(7)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(7)" /><published>2025-05-26T15:07:00+00:00</published><updated>2025-05-26T15:07:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(7)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(7)/"><![CDATA[<h2 id="human-in-the-loop-변경">Human in the Loop 변경</h2>
<p>중단점이 사용자 승인을 지원하는 방법을 보여드렸지만 그래프가 중단된 후 그래프 상태를 수정하는 방법에 대해서는 아직 설명드리지 않았습니다.</p>

<p>이제 그래프 상태를 직접 편집하고 사람의 피드백을 입력하는 방법을 보여드리겠습니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>
<h2 id="상태-수정">상태 수정</h2>

<p>이전에는 중단점을 도입했습니다.</p>

<p>그래프를 중단하고 다음 노드를 실행하기 전에 사용자의 승인을 기다리는 데 사용했습니다.</p>

<p>하지만 중단점은 그래프 상태를 수정할 수 있는 기회이기도 합니다.</p>

<p>어시스턴트 노드 앞에 중단점이 있는 에이전트를 설정해 보겠습니다.</p>

<h2 id="툴-선언">툴 선언</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]
llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode

from langchain_core.messages import HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine the control flow
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")

memory = MemorySaver()
graph = builder.compile(interrupt_before=["assistant"], checkpointer=memory)

# Show
display(Image(graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>

<p><img src="/assets/images/post_img/langgraph7.png" alt="langgraph7" /></p>

<p>수행해 봅시다.</p>

<p>채팅 모델이 응답하기 전에 그래프가 중단된 것을 볼 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Input
initial_input = {"messages": "Multiply 2 and 3"}

# Thread
thread = {"configurable": {"thread_id": "1"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('assistant',)
</code></pre></div></div>

<p>이제 상태 업데이트를 직접 적용할 수 있습니다.</p>

<p>메시지 키에 대한 업데이트는 add_messages 리듀서를 사용할 수 있습니다.</p>

<ul>
  <li>기존 메시지를 덮어쓰려면 메시지 ID를 제공하면 됩니다.</li>
  <li>단순히 메시지 목록에 추가하려는 경우 아래와 같이 ID를 지정하지 않고 메시지를 전달할 수 있습니다.</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.update_state(
    thread,
    {"messages": [HumanMessage(content="No, actually multiply 3 and 3!")]},
)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
================================ Human Message =================================

Multiply 2 and 3
('assistant',)
{'configurable': {'thread_id': '1',
  'checkpoint_ns': '',
  'checkpoint_id': '1eff2610-691e-624f-8001-9d5f35e0e8e0'}}
</code></pre></div></div>

<p>한 번 살펴봅시다.</p>

<p>update_state를 호출하여 새메세지로 업데이트하였습니다.</p>

<p>add_messages 리듀서는 이를 상태 키인 메시지에 추가합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>new_state = graph.get_state(thread).values
for m in new_state['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
================================ Human Message =================================

No, actually multiply 3 and 3!
</code></pre></div></div>

<p>이제 에이전트에 None을 전달하고 현재 상태에서 진행하도록 허용하여 진행하겠습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

No, actually multiply 3 and 3!
================================== Ai Message ==================================

[{'type': 'text', 'text': "Okay, let's multiply 3 and 3:"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 3, 'b': 3}, 'id': 'tooluse_a-AWT-oiRv27JR1vq-enDQ'}]
Tool Calls:
  multiply (tooluse_a-AWT-oiRv27JR1vq-enDQ)
 Call ID: tooluse_a-AWT-oiRv27JR1vq-enDQ
  Args:
    a: 3
    b: 3
================================= Tool Message =================================
Name: multiply

9
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('assistant',)
</code></pre></div></div>

<p>이제 중단점이 있는 어시스턴트로 돌아왔습니다.</p>

<p>다시 None을 전달하여 계속 진행하면 됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================= Tool Message =================================
Name: multiply

9
================================== Ai Message ==================================

The result of multiplying 3 and 3 is 9.
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>()
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[Human in the Loop 변경을 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(6)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(6)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(6)" /><published>2025-05-26T15:06:00+00:00</published><updated>2025-05-26T15:06:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(6)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(6)/"><![CDATA[<h2 id="human-in-the-loop">Human in the Loop</h2>

<p>이제 휴먼 인 더 루프가 필요한 배경에 대해 이야기해 보겠습니다:</p>

<p>(1) 승인 - 에이전트를 중단하고 사용자에게 상태를 표시하고 사용자가 작업을 수락하도록 허용할 수 있습니다.</p>

<p>(2) 디버깅 - 그래프를 되감아 문제를 재현하거나 피할 수 있습니다.</p>

<p>(3) 편집 - 상태를 수정할 수 있습니다.</p>

<p>LangGraph는 다양한 휴먼 인 더 루프 워크플로우를 지원하기 위해 에이전트 상태를 가져오거나 업데이트하는 여러 가지 방법을 제공합니다.</p>

<p>먼저 특정 단계에서 그래프를 멈추는 간단한 방법을 제공하는 <code class="language-plaintext highlighter-rouge">breakpoints</code>를 소개하겠습니다.</p>

<p>이를 통해 어떻게 사용자 승인을 지원하는지 보여드리겠습니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

</code></pre></div></div>

<h2 id="human-승인을-위한-breakpoint">Human 승인을 위한 breakpoint</h2>
<p>이전 모듈에서 작업했던 간단한 에이전트를 다시 생각해 보겠습니다.</p>

<p>에이전트가 도구를 사용할 수 있도록 승인하고 싶다고 가정해 보겠습니다.</p>

<p>여기서 <code class="language-plaintext highlighter-rouge">tools</code> 는 도구 노드입니다. <code class="language-plaintext highlighter-rouge">interrupt_before=["tools"]</code>로 그래프를 컴파일하기만 하면 됩니다.</p>

<p>이렇게 하면, 도구 호출을 실행하는 도구 노드 전에 실행이 중단됩니다.</p>

<h2 id="툴-정의">툴 정의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]
llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<h2 id="그래프-정의">그래프 정의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine the control flow
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")

memory = MemorySaver()
graph = builder.compile(interrupt_before=["tools"], checkpointer=memory)

# Show
display(Image(graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>

<p><img src="/assets/images/post_img/langgraph6.png" alt="langgraph6" /></p>

<h2 id="수행-테스트">수행 테스트</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Input
initial_input = {"messages": HumanMessage(content="Multiply 2 and 3")}

# Thread
thread = {"configurable": {"thread_id": "1"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_4-zyUmE8QkyCpyZdpa60FA'}]
Tool Calls:
  multiply (tooluse_4-zyUmE8QkyCpyZdpa60FA)
 Call ID: tooluse_4-zyUmE8QkyCpyZdpa60FA
  Args:
    a: 2
    b: 3
</code></pre></div></div>

<p>상태를 확인하고 다음 호출할 노드를 확인할 수 있습니다.
그래프가 중단된 것을 확인할 수 있는 좋은 방법입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('tools',)
</code></pre></div></div>
<p>이제 멋진 트릭을 소개하겠습니다.
<code class="language-plaintext highlighter-rouge">None</code>으로 그래프를 호출하면 마지막 상태 체크포인트부터 계속됩니다!</p>

<p>명확히 하기 위해 LangGraph는 도구 호출과 함께 <code class="language-plaintext highlighter-rouge">AIMessage</code>가 포함된 현재 상태를 다시 전송합니다.</p>

<p>그런 다음 그래프에서 도구 노드부터 시작되는 다음 단계를 실행합니다.</p>

<p>이 도구 호출로 도구 노드가 실행되고 최종 답변을 위해 채팅 모델에 다시 전달되는 것을 볼 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_4-zyUmE8QkyCpyZdpa60FA'}]
Tool Calls:
  multiply (tooluse_4-zyUmE8QkyCpyZdpa60FA)
 Call ID: tooluse_4-zyUmE8QkyCpyZdpa60FA
  Args:
    a: 2
    b: 3
================================= Tool Message =================================
Name: multiply

6
================================== Ai Message ==================================

The result of multiplying 2 and 3 is 6.
</code></pre></div></div>

<p>이제 이를 사용자 입력을 수락하는 구체적인 사용자 승인 단계와 결합해 보겠습니다.</p>

<h2 id="사용자-승인">사용자 승인</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Input
initial_input = {"messages": HumanMessage(content="Multiply 2 and 3")}

# Thread
thread = {"configurable": {"thread_id": "2"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()

# Get user feedback
user_approval = input("Do you want to call the tool? (yes/no): ")

# Check approval
if user_approval.lower() == "yes":
    
    # If approved, continue the graph execution
    for event in graph.stream(None, thread, stream_mode="values"):
        event['messages'][-1].pretty_print()
        
else:
    print("Operation cancelled by user.")
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_-sDfPvjsQYyb_oGcepgxbA'}]
Tool Calls:
  multiply (tooluse_-sDfPvjsQYyb_oGcepgxbA)
 Call ID: tooluse_-sDfPvjsQYyb_oGcepgxbA
  Args:
    a: 2
    b: 3
Do you want to call the tool? (yes/no):  yes
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_-sDfPvjsQYyb_oGcepgxbA'}]
Tool Calls:
  multiply (tooluse_-sDfPvjsQYyb_oGcepgxbA)
 Call ID: tooluse_-sDfPvjsQYyb_oGcepgxbA
  Args:
    a: 2
    b: 3
================================= Tool Message =================================
Name: multiply

6
================================== Ai Message ==================================

The result of multiplying 2 and 3 is 6..
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[휴먼 인 더 루프를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(5)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(5)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(5)" /><published>2025-05-26T15:05:00+00:00</published><updated>2025-05-26T15:05:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(5)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(5)/"><![CDATA[<h2 id="상태-스키마">상태 스키마</h2>

<p>이 모듈에서는 상태를 저장하는 스키마와 이와 연관된 메모리에 대해서 좀 더 알아보겠습니다.</p>

<h2 id="bedrock-setting">Bedrock Setting</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>
<h2 id="스키마">스키마</h2>

<p>LangGraph에서 <code class="language-plaintext highlighter-rouge">StateGraph</code>를 정의할 때, 우리는 상태스키마를 사용합니다.</p>

<p>상태 스키마는 그래프가 사용하는 데이터를 저장하기 위한 데이터 구조와 데이터 타입을 말합니다.</p>

<p>그래프를 초기 선언할 때, 정의하면, 모든 노드들이 이 상태 스키마를 이용해서 커뮤니케이션합니다.</p>

<p>LangGraph에는 이 상태스키마를 정의해서 사용할 때, 유연한 구성 옵션들을 제공합니다. 그래서 다양한 Python 타입들을 수용하고, 다양한 접근 방법들을 제공합니다.</p>

<h2 id="typeddict">TypedDict</h2>

<p>상태스키마에서 기본적으로 사용하는 클래스 타입은 <code class="language-plaintext highlighter-rouge">TypedDict</code> 입니다.</p>

<p>이 클래스타입은, key를 명시하고, 그에 해당하는 값을 지정하는 것을 지원합니다.</p>

<p>하지만, 엄격하게 데이터타입을 규정해야 하는 업무에서는 <code class="language-plaintext highlighter-rouge">TypedDict</code> 기능 만으로는 부족합니다.</p>

<p>아래는 TypedDict의 예시입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from typing_extensions import TypedDict

class TypedDictState(TypedDict):
    foo: str
    bar: str
</code></pre></div></div>
<p>좀더 명확하게 데이터타입을 규정해서 해당 타입을 사용해야한다라고 하면, <code class="language-plaintext highlighter-rouge">Literal</code> 타입을 쓸 수 있습니다.</p>

<p>아래 예시에서 볼 수 있듯이, <code class="language-plaintext highlighter-rouge">mood</code>는 “happy”나 “sad”만 될 수 있습니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from typing import Literal

class TypedDictState(TypedDict):
    name: str
    mood: Literal["happy","sad"]
</code></pre></div></div>
<p>랭그래프에서 <code class="language-plaintext highlighter-rouge">StateGraph</code>를 입력하여, 우리는 사전정의된 상태 클래스를 사용할 수 있습니다.</p>

<p>그리고, 우리는 각 상태키는 전체 그래프의 커뮤니케이션에서 “채널” 역할로 수행하게 할 수 있습니다.</p>

<p>우리는 각 노드에서 상태그래프에 있는 상태키를 바꿀 수 있습니다.</p>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import random
from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END

def node_1(state):
    print("---Node 1---")
    return {"name": state['name'] + " is ... "}

def node_2(state):
    print("---Node 2---")
    return {"mood": "happy"}

def node_3(state):
    print("---Node 3---")
    return {"mood": "sad"}

def decide_mood(state) -&gt; Literal["node_2", "node_3"]:
        
    # Here, let's just do a 50 / 50 split between nodes 2, 3
    if random.random() &lt; 0.5:

        # 50% of the time, we return Node 2
        return "node_2"
    
    # 50% of the time, we return Node 3
    return "node_3"

# Build graph
builder = StateGraph(TypedDictState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph5.png" alt="langgraph5" /></p>

<p>스테이트는 딕셔너리이므로 딕셔너리로 그래프를 호출하여 스테이트의 <code class="language-plaintext highlighter-rouge">name</code> 키의 초기 값을 설정하기만 하면 됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke({"name":"Lance"})
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 3---
{'name': 'Lance is ... ', 'mood': 'sad'}
</code></pre></div></div>

<h2 id="dataclass">Dataclass</h2>

<p>파이썬의 데이터클래스는 구조화된 데이터를 정의하는 또 다른 방법을 제공합니다.</p>

<p>데이터클래스는 주로 데이터를 저장하는 데 사용되는 클래스를 생성하기 위한 간결한 구문을 제공합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from dataclasses import dataclass

@dataclass
class DataclassState:
    name: str
    mood: Literal["happy","sad"]
</code></pre></div></div>
<p>데이터클래스의 키에 액세스하려면 node_1에서 사용된 상태스키마를 수정하기만 하면 됩니다:</p>

<p>데이터 클래스 상태에는 위의 TypedDict에 state[“name”]이 아닌 state.name을 사용합니다.</p>

<p>LangGraph가 상태 객체의 각 키를 개별적으로 저장합니다.</p>

<p>노드가 반환하는 객체에는 상태의 키(속성)와 일치하는 키만 있으면 됩니다!</p>

<p>이 경우 데이터클래스에 키 이름이 있으므로 state가 TypedDict일 때와 마찬가지로 노드에서 딕셔너리를 전달하여 업데이트할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def node_1(state):
    print("---Node 1---")
    return {"name": state.name + " is ... "}

# Build graph
builder = StateGraph(DataclassState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph5.png" alt="langgraph5" /></p>

<p>데이터클래스로 호출하여 스테이트의 각 키/채널의 초기값을 설정합니다!
아래와 같이 초기값을 설정하여 수행하도록 유도할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke(DataclassState(name="Lance",mood="sad"))
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 3---
{'name': 'Lance is ... ', 'mood': 'sad'}
</code></pre></div></div>

<h2 id="pydantic">Pydantic</h2>

<p>앞서 언급했듯이 TypedDict와 데이터클래스는 타입 힌트를 제공하지만 런타임에 타입을 강제하지는 않습니다.</p>

<p>즉, 오류를 발생시키지 않고 잘못된 값을 할당할 수 있습니다!</p>

<p>예를 들어, 유형 힌트에 무드가 지정되어 있어도 무드를 mad로 설정할 수 있습니다: <code class="language-plaintext highlighter-rouge">mood: list[Literal["happy","sad"]]</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataclass_instance = DataclassState(name="Lance", mood="mad")
</code></pre></div></div>

<p>Pydantic은 Python 유형 주석을 사용하는 데이터 유효성 검사 및 설정 관리 라이브러리입니다.</p>

<p>유효성 검사 기능으로 인해 LangGraph에서 상태 스키마를 정의하는 데 특히 적합합니다.</p>

<p>Pydantic은 유효성 검사를 수행하여 런타임에 데이터가 지정된 유형과 제약 조건을 준수하는지 확인할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from pydantic import BaseModel, field_validator, ValidationError

class PydanticState(BaseModel):
    name: str
    mood: str # "happy" or "sad" 

    @field_validator('mood')
    @classmethod
    def validate_mood(cls, value):
        # Ensure the mood is either "happy" or "sad"
        if value not in ["happy", "sad"]:
            raise ValueError("Each mood must be either 'happy' or 'sad'")
        return value

try:
    state = PydanticState(name="John Doe", mood="mad")
except ValidationError as e:
    print("Validation Error:", e)
</code></pre></div></div>

<p>이런 Pydantic의 기능을 이용해서 그래프에서 PydanticState를 원활하게 사용할 수 있습니다.</p>

<h2 id="그래프-생성-1">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Build graph
builder = StateGraph(PydanticState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph5.png" alt="langgraph5" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke(PydanticState(name="Lance",mood="sad"))
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 2---
{'name': 'Lance is ... ', 'mood': 'happy'}
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[상태 스키마를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(4)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(4)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(4)" /><published>2025-05-26T15:04:00+00:00</published><updated>2025-05-26T15:04:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(4)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(4)/"><![CDATA[<h2 id="그래프-메모리란">그래프 메모리란?</h2>
<p>Agent를 통해서 처리되는 것들을 살펴 보았습니다.
하지만, LLM은 기본적으로 사용자가 수행하는 대화를 기억하지 못합니다.
그래서 그래프에서도 사용자가 수행하는 대화를 기억할 수 있도록 하는 장치가 필요합니다.
그래서 그래프 메모리는 이렇게 사용자가 수행한 대화를 기억할 수 있도록 도와서 컨텍스트에 맞는 답변을 하도록 도움을 줍니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>
<h2 id="툴-생성">툴 생성</h2>
<p>이전 실습과 동일하게 아래와 같은 툴들을 생성합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Divide a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]
llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<h2 id="assistant-함수-정의">Assistant 함수 정의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import MessagesState
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode
from IPython.display import Image, display

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine how the control flow moves
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")
react_graph = builder.compile()

# Show
display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph4.png" alt="langgraph4" /></p>

<h1 id="메모리-관련-수행-테스트">메모리 관련 수행 테스트</h1>

<p>생성된 그래프 에이전트를 아래와 같이 수행합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Add 3 and 4.")]
messages = react_graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_H7NSwbEZTly89MQ_60KYfg'}]
Tool Calls:
  add (tooluse_H7NSwbEZTly89MQ_60KYfg)
 Call ID: tooluse_H7NSwbEZTly89MQ_60KYfg
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

The result of adding 3 and 4 is 7.
</code></pre></div></div>

<h2 id="메모리-없이-수행-테스트테스트">메모리 없이 수행 테스트테스트</h2>
<p>이 상태에서 앞의 결과를 참조해서 아래와 같이 질문합니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Multiply that by 2.")]
messages = react_graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply that by 2.
================================== Ai Message ==================================

[{'type': 'text', 'text': "Okay, let's multiply the previous result by 2."}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': '$PREVIOUS_RESULT', 'b': 2}, 'id': 'tooluse_P1TkD006QBSvvAITldWUyg'}]
Tool Calls:
  multiply (tooluse_P1TkD006QBSvvAITldWUyg)
 Call ID: tooluse_P1TkD006QBSvvAITldWUyg
  Args:
    a: $PREVIOUS_RESULT
    b: 2
================================= Tool Message =================================
Name: multiply

Error: 1 validation error for multiply
a
  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='$PREVIOUS_RESULT', input_type=str]
    For further information visit https://errors.pydantic.dev/2.9/v/int_parsing
 Please fix your mistakes.
================================== Ai Message ==================================

Oops, it looks like I don't have a previous result stored. Could you please provide the number you would like me to multiply by 2?
</code></pre></div></div>

<h2 id="메모리를-활용한-수행-테스트">메모리를 활용한 수행 테스트</h2>
<p>에이전트는 이전 결과값을 알 지 못해서 위의 결과와 같이 계산을 할 수 없다고 답변합니다.</p>

<p>그 이유는 LLM은 사용자의 대화를 기억하지 못하기 때문입니다.</p>

<p>그래서, 이런 방식으로 그대로 수행하게 되면, 멀티턴을 이용하는 대화방식을 구현이 쉽지 않습니다.</p>

<p>그래서, 여기에서 우리는 <code class="language-plaintext highlighter-rouge">persistence</code> 아키텍처를 이용할 수 있습니다.</p>

<p>LangGraph에서는 <code class="language-plaintext highlighter-rouge">checkpointer</code>라는 개념을 이용해서, 그래프의 상태를 저장하도록 할 수 있습니다.</p>

<p>LangGraph에서 자체 지원하는 persistence 레이어는 memory로 구성하는 것을 지원합니다. 이를 통해서 마지막 대화나, 진행 상태에 대해서 정보를 참조할 수 있습니다.</p>

<p>가장 쉽게 구현할 수 있는 <code class="language-plaintext highlighter-rouge">Checkpointer</code>는 <code class="language-plaintext highlighter-rouge">MemorySaver</code>입니다. <code class="language-plaintext highlighter-rouge">MemorySaver</code>는 그래프 상태를 저장할 수 있는 key-value 스토업니다.</p>

<p>이를 구현하는 방법은 간단합니다.
그래프르 컴파일할 때, checkpointer 아규먼트와 함께 컴파일하면 됩니다. 그러면, 그래프는 메모리를 갖게 됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.checkpoint.memory import MemorySaver
memory = MemorySaver()
react_graph_memory = builder.compile(checkpointer=memory)
</code></pre></div></div>

<p>실제로 대화가 이루어질 때는 어려사용자들이 동시에 사용하게 됩니다.
그래서 사용자는 세션을 구분하기위한 장치가 필요합니다.
그래서, 그래프에서 메모리를 사용할 때는 <code class="language-plaintext highlighter-rouge">thread_id</code> 아규먼트를 이용해서 세션을 구분하도록 합니다.</p>

<p>This <code class="language-plaintext highlighter-rouge">thread_id</code> will store our collection of graph states.
이 <code class="language-plaintext highlighter-rouge">thread_id</code>를 통해서 그래프 상태를 저장할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Specify a thread
config = {"configurable": {"thread_id": "1"}}

# Specify an input
messages = [HumanMessage(content="Add 3 and 4.")]

# Run
messages = react_graph_memory.invoke({"messages": messages},config)
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_p4Z-a9woSemlo7TWzNaH5Q'}]
Tool Calls:
  add (tooluse_p4Z-a9woSemlo7TWzNaH5Q)
 Call ID: tooluse_p4Z-a9woSemlo7TWzNaH5Q
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

The result of adding 3 and 4 is 7.
</code></pre></div></div>
<p>위에서 수행한 결과에 대해서 <code class="language-plaintext highlighter-rouge">thread_id</code>를 통해서 메모리 처리가 잘 되는지를 확인해 볼 수 있습니다.
<code class="language-plaintext highlighter-rouge">thread_id</code>를 통해서 이전에 수행한 결과를 참조해 볼 수 있습니다.</p>

<p>이 예시에서 볼 수 있듯이, 이전에 수행한 대화를 참조할 수 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">HumanMessage</code>에 <code class="language-plaintext highlighter-rouge">"Multiply that by 2."</code>라는 메세지를 수행하면, 이전 대화의 내용에 append 되어 저장됩니다.</p>

<p>그래서 이제 모델은 <code class="language-plaintext highlighter-rouge">that</code>이라는 지시어가 이전에 문의한 질문에 대한 답변인 <code class="language-plaintext highlighter-rouge">The sum of 3 and 4 is 7.</code> 임을 알게됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Multiply that by 2.")]
messages = react_graph_memory.invoke({"messages": messages}, config)
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_p4Z-a9woSemlo7TWzNaH5Q'}]
Tool Calls:
  add (tooluse_p4Z-a9woSemlo7TWzNaH5Q)
 Call ID: tooluse_p4Z-a9woSemlo7TWzNaH5Q
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

The result of adding 3 and 4 is 7.
================================ Human Message =================================

Multiply that by 2.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 7, 'b': 2}, 'id': 'tooluse_QPBCvXWOQwGLCH4mudVp7Q'}]
...
14
================================== Ai Message ==================================

The result of multiplying 7 by 2 is 14.
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[그래프 메모리를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(3)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(3)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(3)" /><published>2025-05-26T15:03:00+00:00</published><updated>2025-05-26T15:03:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(3)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(3)/"><![CDATA[<h2 id="툴-에이전트-실습">툴 에이전트 실습</h2>

<p>앞에서 라우터를 실습해 봤기 때문에, 여기에서는 좀 더 해당 개념을 확장해서 수행할 예정입니다.</p>

<p>우리는 앞의 라우터 실습에서, LLM에게 질의를 하였고, 만약에 질의의 내용이 툴을 호출하는 것이라면, <code class="language-plaintext highlighter-rouge">ToolMessage</code>를 통해서 답변을 하는 것을 보았습니다.</p>

<p>이번에는, ToolMessage를 바로 사용자에게 답변하는 것이 아니라, 이 메세지를 다시 모델에게 전달할 수 있을까요?</p>

<p>그래서 이번에는 툴을 통해서 나온 답변을 이용해서 또 다른 툴에게 인풋으로 사용하라고 전달하거나, 바로 사용자에게 답변이 가능한지를 실험해 보도록 하겠습니다.</p>

<p>이러한 접근 방식이 기본적인 ReAct에서 수행하는 접근법과 동일한 접근법입니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">act</code> - 모델이 툴을 사용합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">observe</code> - 툴의 결과값을 다시 모델에게 전달합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">reason</code> - 툴의 결과값에 대해서 다른 툴을 호출해야 되는지 등에 대한 reasoning을 수행합니다.</li>
</ul>

<p>이 접근법은 다양한 Agent 아키텍처에서 공통으로 활용될 수 있습니다.</p>

<h2 id="bedrock-setup">Bedrock Setup</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

</code></pre></div></div>

<h2 id="여러개의-툴들을-정의">여러개의 툴들을 정의</h2>

<p>아래와 같이, 덧셈, 곱셈, 나눗셈 툴을 정의합니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Divide a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]

llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<p>LLM assitant를 만들어서 전체적인 agent 동작을 관장하도록 합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}
</code></pre></div></div>

<p>이전에는 <code class="language-plaintext highlighter-rouge">Tools</code> 노드를 생성해서 이 노드에서 툴들을 처리하도록 하였습니다.</p>

<p>이번에는 <code class="language-plaintext highlighter-rouge">Assistant</code> 노드를 만들었고, 이 노드에서 LLM이 명시적으로 동작하도록 세팅하고 있습니다.</p>

<p>마찬가지로 <code class="language-plaintext highlighter-rouge">Assistant</code>와 <code class="language-plaintext highlighter-rouge">Tools</code> 노드를 생성합니다.</p>

<p>그리고 <code class="language-plaintext highlighter-rouge">tools_condition</code> 엣지르를 구성합니다. 이 엣지는 입력되는 요건에 따라서 툴을 사용하게 할 것인지, 바로 답변을 수행해서 <code class="language-plaintext highlighter-rouge">End</code> 노드로 분기하도록 할지를 결정합니다.</p>

<p>그리고 한가지 단계가 더 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">Tools</code>에 대한 답변을 다시 <code class="language-plaintext highlighter-rouge">Assistant</code>노드로 전달하도록 루프를 생성합니다. 이 루프는 아래와 같은 방식으로 동작합니다.</p>

<ul>
  <li>최초에 <code class="language-plaintext highlighter-rouge">assistant</code> 노드가 수행된 이후에, <code class="language-plaintext highlighter-rouge">tools_condition</code>이 툴을 수행할 것인지를 결정합니다.</li>
  <li>Tool call이 결정된다면, <code class="language-plaintext highlighter-rouge">tools</code>노드가 수행되도록 분기합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">tools</code>의 수행결과는 다시 <code class="language-plaintext highlighter-rouge">assistant</code>노드로 되돌아갑니다.</li>
  <li>이 루프는 <code class="language-plaintext highlighter-rouge">assistant</code> 노드에서 툴 호출이 계속적으로 필요하다고 판단된다면, 계속적으로 수행합니다.</li>
  <li>모델의 결과가 툴 호출이 더 이상 필요하지 않다고 판단된다면, 플로우는 END노드로 넘어갑니다. 이로서 모든 수행이 끝납니다.</li>
</ul>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langgraph.prebuilt import ToolNode
from IPython.display import Image, display

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine how the control flow moves
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")
react_graph = builder.compile()

# Show
display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph3.png" alt="langgraph3" /></p>

<h2 id="그래프-수행-테스트">그래프 수행 테스트</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Add 3 and 4. Multiply the output by 2. Divide the output by 5")]
messages = react_graph.invoke({"messages": messages})
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4. Multiply the output by 2. Divide the output by 5
================================== Ai Message ==================================

[{'type': 'text', 'text': "Okay, let's do that step-by-step:"}, {'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_u8LY5iziQtu7L-LLq_AlRw'}]
Tool Calls:
  add (tooluse_u8LY5iziQtu7L-LLq_AlRw)
 Call ID: tooluse_u8LY5iziQtu7L-LLq_AlRw
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 7, 'b': 2}, 'id': 'tooluse_gxPpRu89TfWwIfjF2fQAQw'}]
Tool Calls:
  multiply (tooluse_gxPpRu89TfWwIfjF2fQAQw)
 Call ID: tooluse_gxPpRu89TfWwIfjF2fQAQw
  Args:
    a: 7
    b: 2
...
2.8
================================== Ai Message ==================================

So the final result is 2.8.
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[툴 에이전트를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(2)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(2)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(2)" /><published>2025-05-26T15:02:00+00:00</published><updated>2025-05-26T15:02:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(2)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(2)/"><![CDATA[<h2 id="라우터란">라우터란?</h2>

<p>사용자의 인풋에 따라서, Gen AI를 컨텍스트에 맞는 답변을 수행해야 하는지를 판단하게 할 수 있습니다.
이러한 작업을 수행하는 것이 라우터입니다.
그래서 사용자의 컨텍스트에 맞게 해당되는 툴로 답변을 유도하거나, LLM이 스스로 답변하는 형태로 답변하도록 합니다.</p>

<p>이 실습예제도 사용자의 요청에 따라서 툴을 사용하거난, LLM을 통해서 직접 답변하게는 등의 수행이 제대로 되는지를 실습해 볼 예정입니다.</p>

<p>이러한 라우터 방식이 동작하게 하기 위해서 아래의 2가지 형태를 준비할 예정입니다.</p>
<ul>
  <li>우선 툴을 사용하는 노드를 구성합니다.</li>
  <li>그리고 조건부 엣지를 생성합니다. 이 조건부 엣지에서는 사용자 인풋에 따라서, 툴을 사용하게 할 것인지, LLM이 직접 답변하게 할 지 등에 대해서 라우터 역할을 수행하게 할 것입니다.</li>
</ul>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AIMessage(content="The Amazon Nova is a line of tablet computers developed and sold by Amazon. Some key details about the Amazon Nova tablets:\n\n- They are part of Amazon's Fire tablet lineup, which also includes the standard Fire tablets and the Fire HD tablets.\n\n- The Amazon Nova tablets are designed to be more premium and higher-end models compared to the standard Fire tablets.\n\n- They typically feature larger screen sizes, more powerful processors, more RAM, and additional storage compared to the base Fire tablets.\n\n- The Amazon Nova tablets run Amazon's Fire OS, which is a customized version of the Android operating system.\n\n- They are primarily designed to integrate with Amazon's ecosystem of services like Amazon Prime, Kindle, Alexa, and Amazon's digital content stores.\n\n- Some recent models in the Amazon Nova line include the Fire HD 10 Plus and the Fire HD 10 Productivity Edition, which are positioned as more advanced and capable tablets.\n\nSo in summary, the Amazon Nova represents Amazon's higher-end tablet offerings that sit above their standard Fire tablet models in terms of features and performance.", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'b2d2e840-07b8-4970-ab9e-d071784071dc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 27 Feb 2025 03:19:58 GMT', 'content-type': 'application/json', 'content-length': '1306', 'connection': 'keep-alive', 'x-amzn-requestid': 'b2d2e840-07b8-4970-ab9e-d071784071dc'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': 2564}}, id='run-1c7d4c35-2075-4e2d-b882-3f38ff843b09-0', usage_metadata={'input_tokens': 13, 'output_tokens': 228, 'total_tokens': 241})
</code></pre></div></div>

<h2 id="툴-함수-생성">툴 함수 생성</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """This tool is to multiply two input argrments such as a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

llm_with_tools = llm.bind_tools([multiply])
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>

<p>우리는 아주 쉽고 간단한 형태로 구현하는 것을 수행해 볼 것입니다.
LangGraph에서 제공하는 <code class="language-plaintext highlighter-rouge">ToolNode</code> 패키지를 이용할 것입니다.
툴노드를 사용하게 되면, 간단하게 생성된 툴들을 이 노드에서 처리하도록 할 수 있습니다.</p>

<p>그리고 Langgraph에서 제공하는 <code class="language-plaintext highlighter-rouge">tools_condition</code>을 조건부 엣지에서 사용할 예정입니다.
이 기능을 사용하게 되면, 사용자의 입력에 따라서 자동으로 어떤 툴들을 사용할지에 대해서 분기합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END
from langgraph.graph import MessagesState
from langgraph.prebuilt import ToolNode
from langgraph.prebuilt import tools_condition

# Node
def tool_calling_llm(state: MessagesState):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

# Build graph
builder = StateGraph(MessagesState)
builder.add_node("tool_calling_llm", tool_calling_llm)
builder.add_node("tools", ToolNode([multiply]))
builder.add_edge(START, "tool_calling_llm")
builder.add_conditional_edges(
    "tool_calling_llm",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", END)
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph2.png" alt="langgraph2" /></p>

<h2 id="일상적인-대화로-질의">일상적인 대화로 질의</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_core.messages import HumanMessage
messages = [HumanMessage(content="안녕 잘 지내?")]
messages = graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

안녕 잘 지내?
================================== Ai Message ==================================

네, 저도 잘 지내고 있습니다. 오늘 날씨가 좋아서 기분이 좋네요. 어떤 계획이 있으신가요? 함께 즐거운 시간을 보내면 좋겠습니다.
</code></pre></div></div>

<h2 id="곱셈을-문의하는-질의">곱셈을 문의하는 질의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="134 곱하기 1435를 계산하면 얼마야?")]
messages = graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

134 곱하기 1435를 계산하면 얼마야?
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 134, 'b': 1435}, 'id': 'tooluse_FYpRmFUlTz6BQRNDuX6Fpg'}]
Tool Calls:
  multiply (tooluse_FYpRmFUlTz6BQRNDuX6Fpg)
 Call ID: tooluse_FYpRmFUlTz6BQRNDuX6Fpg
  Args:
    a: 134
    b: 1435
================================= Tool Message =================================
Name: multiply

192290
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[라우터를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(1)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(1)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(1)" /><published>2025-05-26T15:01:00+00:00</published><updated>2025-05-26T15:01:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(1)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(1)/"><![CDATA[<h2 id="간단한-그래프">간단한 그래프</h2>

<p>LangGraph에서 개념을 갖고 있는 Graph에 대해서 알아보기 위해서, 아주 간단한 그래프를 그려볼 것입니다.
간단한 3개의 노드를 이용해서 그래프를 그려볼 수 있습니다.</p>

<h2 id="패키지-설치">패키지 설치</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%%capture --no-stderr
%pip install --quiet -U langgraph
</code></pre></div></div>

<h2 id="state-상태저장">State (상태저장)</h2>

<p>우선, 그래프의 상태를 저장하는 State class를 우선 정의합니다.
이 상태 스키마는 그래프의 모든 노드에 대한 정보들을 저장하고 처리합니다.</p>

<p>정형화된 데이터 저장을 위해서, 이번 예시에서는 <code class="language-plaintext highlighter-rouge">TypedDict</code> 클래스를 이용해서 State를 생성합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from typing_extensions import TypedDict

class State(TypedDict):
    graph_state: str
</code></pre></div></div>

<h2 id="노드">노드</h2>

<p>그래프에서 각각이 의미있는 수행포인트를 지정하는 것이 노드입니다.</p>

<p>각각의 노드들은 그래프의 현재 상태를 알고 판단을 수행해야 하기 때문에, 위에서 정의한 state 클래스를 입력 아규먼트로 사용합니다.</p>

<p>위에서 State를 정의할 때, graph_state에 대한 멤버변수를 정의했기 때문에, 각 노드에서는 state 클래스의 멤버변수를 접근하여 활용할 수 있습니다.</p>

<p>그리고 각 노드는 처리된 결과를 리턴합니다.</p>

<p>이 예제에서는 각 노드에서 이전 state에 저장된 정보를 계속해서 업데이트하면서 결과가 어떻게 바뀌는지를 확인할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def node_1(state):
    print("---Node 1---")
    return {"graph_state": state['graph_state'] +" I am"}

def node_2(state):
    print("---Node 2---")
    return {"graph_state": state['graph_state'] +" happy!"}

def node_3(state):
    print("---Node 3---")
    return {"graph_state": state['graph_state'] +" sad!"}
</code></pre></div></div>

<h2 id="엣지">엣지</h2>

<p>노드가 각 역할을 수행하는 점들이라고 한다면, 엣지를 각 점들을 연결하는 역할을 수행합니다.</p>

<p>이 방식을 통해서, 각 노드들을 연결하면서, 전체적인 Workflow 그래프를 완성합니다.</p>

<p>기본적인 엣지의 형태는 노드1에서 노드2로 연결하는 역할만 수행합니다.</p>

<p>조건분기 엣지는 입력되는 결과에 따라서 다음에 수행해야 하는 노드를 선택하는 조건을 분기하는 로직을 넣어서 처리하는 역할을 수행합니다. 그래서 분기할 수 있는 로직을 넣어서 처리합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import random
from typing import Literal

def decide_mood(state) -&gt; Literal["node_2", "node_3"]:
    
    # Often, we will use state to decide on the next node to visit
    user_input = state['graph_state'] 
    
    # Here, let's just do a 50 / 50 split between nodes 2, 3
    if random.random() &lt; 0.5:

        # 50% of the time, we return Node 2
        return "node_2"
    
    # 50% of the time, we return Node 3
    return "node_3"
</code></pre></div></div>

<h2 id="그래프-구성">그래프 구성</h2>

<p>이전 과정까지, 노드와 엣지에 대해서 설명했으니, 그래프를 이제 그릴 수 있습니다.</p>

<p>우선, StateGraph를 초기화하여 생성합니다.</p>

<p>그리고, 노드와 엣지를 추가합니다.</p>

<p>그래프를 시작할 때는 <code class="language-plaintext highlighter-rouge">START</code>라는 특수 노드를 우선 정의해야 합니다.
이 노드이 있어야 그래프가 시작할 수 있습니다.</p>

<p>마찬가지로, <code class="language-plaintext highlighter-rouge">END</code>라는 특수 노드를 정의해야 합니다.
이 노드를 통해서 그래프의 최종 상태를 정의할 수 있습니다.</p>

<p>마지막으로 이렇게 정의된 내용들을 <code class="language-plaintext highlighter-rouge">compile</code>하면 그래프가 완성됩니다.</p>

<p>그리고 이렇게 만들어진 그래프를 Mermain diagram 기능을 이용해서 그래프를 png 파일로 visualize 할 수 있습니다.
이렇게 Visualization 방식을 통해서 그래프를 빠르게 이해할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def dummy_func(state) -&gt; Literal["node_2", "node_3"]:
    
    # Often, we will use state to decide on the next node to visit
    user_input = state['graph_state']

    return "node_2"
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END

# Build graph
builder = StateGraph(State)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", dummy_func)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph1.png" alt="langgraph1" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END


# Build graph
builder = StateGraph(State)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>

<h2 id="그래프-호출">그래프 호출</h2>

<p>The compiled graph implements the <a href="https://python.langchain.com/v0.1/docs/expression_language/interface/">runnable</a> protocol.
이렇게 컴파일된 그래프는 LangChain의 <code class="language-plaintext highlighter-rouge">runnable</code>로 동작합니다.</p>

<p>이 방식은 LangChain 콤포넌트들을 효과적으로 처리합니다.</p>

<p><code class="language-plaintext highlighter-rouge">invoke</code>는 이러한 <code class="language-plaintext highlighter-rouge">runnable</code> 동작 아키텍처의 기본적인 호출 방식입니다.</p>

<p>여기에서 처음 수행해 보는 예시는 <code class="language-plaintext highlighter-rouge">{"graph_state": "Hi, this is lance."}</code>형태로 아주 간단한 메세지를 전달하는 것입니다. 그래프의 상태를 dict 형태로 정의했기 때문에, dict 형태의 메세지로 만들어서 호출합니다. 이 메세지를 인풋값으로 초기에 호출합니다.</p>

<p>이 <code class="language-plaintext highlighter-rouge">invoke</code>가 그래프를 통해서 호출되면, 그래프는 <code class="language-plaintext highlighter-rouge">START</code> 노드에서부터 진행을 시작합니다.</p>

<p>그러면 각 노드들은 차례대로 진행합니다.</p>

<p>조건분기 엣지에서는 랜덤 로직을 구현하였습니다. 그래서 노드2와 노드3를 50%의 확률로 번갈아가면서 호출합니다.</p>

<p>각 노드 함수는 현재 상태를 수신하니다. 그리고 처리된 결과를 graph state 클래스에 업데이트합니다.</p>

<p>이 수행은 <code class="language-plaintext highlighter-rouge">END</code>노드에 다달을 때까지 지속합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke({"graph_state" : "Hi, this is Lance."})
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 3---
{'graph_state': 'Hi, this is Lance. I am sad!'}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">invoke</code> 는 그래프에서 동기방식으로 동작합니다.</p>

<p>그래서, 이전 단계가 완전히 끝나기를 기다렸다가 수행합니다.</p>

<p>모든 노드의 수행이 끝나면 마지막 graph state 값을 출력합니다.</p>

<p>이 예시에서는 노드2나 노드3이 완전히 끝나고 나서 결과를 출력합니다. 아래와 같은 결과가 출력됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'graph_state': 'Hi, this is Lance. I am sad!'}
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[그래프를 알아보자]]></summary></entry><entry><title type="html">ALB, NLB, CLB, GWLB – AWS 로드 밸런서 완전 정리</title><link href="https://aidendef.github.io//cloud/ALB,-NLB,-CLB,-GWLB-AWS-%EB%A1%9C%EB%93%9C-%EB%B0%B8%EB%9F%B0%EC%84%9C-%EC%99%84%EC%A0%84-%EC%A0%95%EB%A6%AC/" rel="alternate" type="text/html" title="ALB, NLB, CLB, GWLB – AWS 로드 밸런서 완전 정리" /><published>2025-05-19T15:00:00+00:00</published><updated>2025-05-19T15:00:00+00:00</updated><id>https://aidendef.github.io//cloud/ALB,%20NLB,%20CLB,%20GWLB%20%E2%80%93%20AWS%20%EB%A1%9C%EB%93%9C%20%EB%B0%B8%EB%9F%B0%EC%84%9C%20%EC%99%84%EC%A0%84%20%EC%A0%95%EB%A6%AC</id><content type="html" xml:base="https://aidendef.github.io//cloud/ALB,-NLB,-CLB,-GWLB-AWS-%EB%A1%9C%EB%93%9C-%EB%B0%B8%EB%9F%B0%EC%84%9C-%EC%99%84%EC%A0%84-%EC%A0%95%EB%A6%AC/"><![CDATA[<h2 id="1-들어가며">1. 들어가며</h2>

<p>AWS에서 서비스를 운영하다 보면, 로드 밸런서는 거의 필수다.<br />
하지만 ELB 안에도 종류가 4가지나 있어서 처음 접하면 헷갈리기 쉽다.</p>

<ul>
  <li>웹 서비스엔 ALB?</li>
  <li>게임 서버엔 NLB?</li>
  <li>옛날 시스템은 CLB?</li>
  <li>방화벽 연결엔 GWLB?</li>
</ul>

<p>이번 글에서는 AWS의 로드 밸런서 종류를 한 번에 정리해보고, 각 로드 밸런서가 어떤 상황에 적합한지 사례를 들어가며 설명해보려고 한다.</p>

<hr />

<h2 id="2-전체-비교표로-빠르게-보기">2. 전체 비교표로 빠르게 보기</h2>

<table>
  <thead>
    <tr>
      <th>종류</th>
      <th>풀네임</th>
      <th>계층</th>
      <th>주요 목적</th>
      <th>특징 요약</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ALB</td>
      <td>Application Load Balancer</td>
      <td>L7</td>
      <td>HTTP/HTTPS 트래픽 처리</td>
      <td>경로/호스트 기반 라우팅, 웹 앱에 특화</td>
    </tr>
    <tr>
      <td>NLB</td>
      <td>Network Load Balancer</td>
      <td>L4</td>
      <td>TCP/UDP 기반 초고속 통신</td>
      <td>정적 IP, TLS 종료 가능, 초고성능</td>
    </tr>
    <tr>
      <td>CLB</td>
      <td>Classic Load Balancer</td>
      <td>L4/L7</td>
      <td>구형 아키텍처 호환</td>
      <td>과거 시스템 유지용, 기능 제한적</td>
    </tr>
    <tr>
      <td>GWLB</td>
      <td>Gateway Load Balancer</td>
      <td>L3/L4</td>
      <td>보안 장비 트래픽 미러링 등 연동</td>
      <td>서드파티 방화벽, IDS 등과 연동 용도</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="3-alb--application-load-balancer">3. ALB – Application Load Balancer</h2>

<p><img src="/assets/images/post_img/Application_Load_Balancer.png" alt="Application_Load_Balancer" /></p>

<p>웹 애플리케이션에 특화된 L7 로드 밸런서이다.<br />
HTTP, HTTPS 트래픽에 대해 경로 기반 또는 호스트 기반 라우팅이 가능하다.</p>

<h3 id="주요-특징">주요 특징</h3>
<ul>
  <li>L7 (Application Layer)에서 동작</li>
  <li><code class="language-plaintext highlighter-rouge">/api</code> → A 서비스, <code class="language-plaintext highlighter-rouge">/admin</code> → B 서비스처럼 경로 기반 분기 가능</li>
  <li>WebSocket, HTTP/2 지원</li>
  <li>대상 그룹: EC2, Lambda, Fargate, IP 등 유연</li>
</ul>

<h3 id="사용-예시">사용 예시</h3>
<ul>
  <li>REST API 서버</li>
  <li>마이크로서비스 기반 아키텍처</li>
  <li>정적 리소스와 동적 컨텐츠를 분리해서 배포할 때</li>
</ul>

<hr />

<h2 id="4-nlb--network-load-balancer">4. NLB – Network Load Balancer</h2>

<p><img src="/assets/images/post_img/Network_Load_Balancer.png" alt="Network_Load_Balancer" /></p>

<p>초당 수백만 요청을 처리할 수 있는 L4 로드 밸런서이다.<br />
게임 서버나 실시간 서비스에 적합하다.</p>

<h3 id="주요-특징-1">주요 특징</h3>
<ul>
  <li>L4 (Transport Layer)에서 TCP/UDP 트래픽 처리</li>
  <li>정적 IP 할당 가능</li>
  <li>TLS 종료 가능 (SSL 인증서 적용)</li>
  <li>초고속 처리: ALB보다 훨씬 빠름</li>
</ul>

<h3 id="사용-예시-1">사용 예시</h3>
<ul>
  <li>온라인 게임 서버</li>
  <li>금융 시스템</li>
  <li>WebRTC 기반 서비스, 실시간 IoT 통신</li>
</ul>

<hr />

<h2 id="5-clb--classic-load-balancer">5. CLB – Classic Load Balancer</h2>

<p><img src="/assets/images/post_img/Classic_Load_Balancer.png" alt="Classic_Load_Balancer" /></p>

<p>예전부터 AWS에서 제공하던 로드 밸런서로, ALB/NLB 이전 세대이다.<br />
L4/L7 모두 지원하지만 기능은 제한적이다.</p>

<h3 id="주요-특징-2">주요 특징</h3>
<ul>
  <li>L4 + L7 혼합 지원</li>
  <li>HTTP 헤더 기반 라우팅은 어려움</li>
  <li>더 이상 신규 권장되지 않음 (기존 유지용)</li>
</ul>

<h3 id="사용-예시-2">사용 예시</h3>
<ul>
  <li>구형 시스템 유지보수</li>
  <li>마이그레이션 전까지 임시 유지</li>
</ul>

<hr />

<h2 id="6-gwlb--gateway-load-balancer">6. GWLB – Gateway Load Balancer</h2>

<p><img src="/assets/images/post_img/Gateway_Load_Balancer.png" alt="Gateway_Load_Balancer" /></p>

<p>L3/L4 계층에서 네트워크 장비와 트래픽을 중계해주는 로드 밸런서이다.<br />
가상 방화벽, IDS/IPS 같은 보안 장비 연동용으로 사용된다.</p>

<h3 id="주요-특징-3">주요 특징</h3>
<ul>
  <li>L3 (Network Layer)에서 동작</li>
  <li>패킷 미러링 및 VPC 트래픽 가시화</li>
  <li>서드파티 네트워크 장비와 연동 가능 (Fortinet, Palo Alto 등)</li>
</ul>

<h3 id="사용-예시-3">사용 예시</h3>
<ul>
  <li>EC2 기반 가상 방화벽 연동</li>
  <li>기업 보안 솔루션 통합</li>
  <li>VPC 내부 트래픽 모니터링</li>
</ul>

<hr />

<h2 id="7-어떤-걸-언제-써야-할까">7. 어떤 걸 언제 써야 할까?</h2>

<table>
  <thead>
    <tr>
      <th>상황</th>
      <th>추천 로드 밸런서</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>웹 서비스, REST API</td>
      <td>ALB</td>
    </tr>
    <tr>
      <td>초고속, 실시간 통신</td>
      <td>NLB</td>
    </tr>
    <tr>
      <td>옛날 시스템 유지</td>
      <td>CLB</td>
    </tr>
    <tr>
      <td>보안 장비 연동</td>
      <td>GWLB</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="8-마무리하며">8. 마무리하며</h2>

<p>로드 밸런서 선택은 단순히 트래픽을 분산시키는 것 이상의 결정이다.<br />
어떤 계층에서 동작하느냐, 어떤 기능이 필요한지에 따라 ALB, NLB, GWLB 중 선택이 갈리게 된다.<br />
CLB는 이제 유지보수 목적으로만 사용하고, 신규 시스템에는 사용을 피하는 것이 좋다.</p>]]></content><author><name>Your Name</name></author><category term="cloud" /><category term="AWS" /><category term="ALB" /><category term="NLB" /><category term="CLB" /><category term="GWLB" /><category term="로드밸런서" /><summary type="html"><![CDATA[AWS 로드 밸런서 4종 완전 비교. 어떤 상황에 어떤 걸 써야 할까?]]></summary></entry><entry><title type="html">AWS Summit Seoul 2025 탐방기</title><link href="https://aidendef.github.io//cloud/AWS-2025-Summit-%ED%83%90%EB%B0%A9%EA%B8%B0/" rel="alternate" type="text/html" title="AWS Summit Seoul 2025 탐방기" /><published>2025-05-18T15:00:00+00:00</published><updated>2025-05-18T15:00:00+00:00</updated><id>https://aidendef.github.io//cloud/AWS%202025%20Summit%20%ED%83%90%EB%B0%A9%EA%B8%B0</id><content type="html" xml:base="https://aidendef.github.io//cloud/AWS-2025-Summit-%ED%83%90%EB%B0%A9%EA%B8%B0/"><![CDATA[<h2 id="1-클라우드의-끝이-아닌-시작점">1. 클라우드의 끝이 아닌, 시작점</h2>

<p><strong>이번 서밋에서 AWS는 더 이상 단순한 인프라 기업이 아니었다.</strong><br />
AI, 서버리스, 지속 가능성까지… 그들의 새로운 ‘무기’는 기존의 패러다임을 완전히 전복시키는 인상을 주었다. 특히 AWS가 강조한 방향성은 ‘모든 기업이 생성형 AI를 바로 실무에 도입할 수 있는 실용성 중심’이었다.</p>

<p><img src="/assets/images/post_img/summit_일정.png" alt="강연일정" /></p>

<p>대표적인 키노트와 세션 주제들은 하나같이 생성형 AI에 집중되어 있었다. 단순한 개념 소개가 아닌, <strong>기업에서 AI를 어떻게 도입하고 프로덕션 워크플로우에 연결하는지에 대한 실질적인 전략</strong>이 강조되었다.</p>

<p>예전엔 AWS Summit이 ‘기술자들을 위한 축제’였다면, 이번 2025년 행사는 <strong>AI 시대의 비즈니스 전략가들을 위한 로드맵 발표회</strong>였다.</p>

<hr />

<h2 id="2-사람-열기-그리고-기대">2. 사람, 열기, 그리고 기대</h2>

<p><img src="/assets/images/post_img/IMG_4627 (2).gif" alt="등록장" /></p>

<p>5월 14일 오전 9시, 코엑스에 도착하자마자 가장 먼저 마주한 것은 <strong>대기 줄과 EDM이 울려 퍼지는 DJ 부스</strong>였다. 예상은 했지만 그 규모와 열기는 여전히 압도적이었다. 등록 부스는 마치 음악 페스티벌의 입구 같았고, 기술 행사의 고정관념을 깨뜨리기에 충분했다.</p>

<p>런치 쿠폰, 네임택을 수령한 뒤 행사장을 돌아보며 곳곳의 부스와 세션을 둘러보기 시작했다.<br />
AWS의 주요 파트너사뿐만 아니라 다양한 업종의 참가 기업들이 자신들의 클라우드 및 AI 도입 사례를 적극적으로 소개하고 있었다.</p>

<p><img src="/assets/images/post_img/IMG_4647.JPG" alt="참가기업위치" />
<img src="/assets/images/post_img/IMG_4648.JPG" alt="참가 스폰서 기업 목록" /></p>

<p>산업군도 매우 다양했다. 제조, 금융, 교육, 엔터테인먼트까지 전방위적으로 클라우드가 확산되고 있다는 것을 실감할 수 있었다. 특히, 모든 기업이 <strong>단순한 ‘클라우드 이전’이 아닌 ‘AI 기반 혁신’을 목표로 하고 있음</strong>이 느껴졌다.</p>

<hr />

<h2 id="3-내가-서밋에-참여한-이유">3. 내가 서밋에 참여한 이유</h2>

<p>이번 서밋 참가 목적은 두 가지였다.</p>

<p><strong>첫째</strong>, 회사에서 준비한 생성형 AI 부스 운영을 지원하기 위해서였다.<br />
직접 데모를 시연하고, 방문객들과 AI 기술에 대한 질의응답을 진행하면서 느낀 것은 <strong>생성형 AI가 더 이상 기술자들만의 언어가 아니라는 점</strong>이다. 일반 관람객, 대학생, 그리고 스타트업 관계자들까지 대부분 LLM, 벡터 DB, RAG 같은 개념에 익숙해 있었다.</p>

<p><strong>둘째</strong>, 다른 기업들은 지금 어떤 기술을, 어떤 방식으로 실험하고 있는지를 알아보기 위해서였다.<br />
이번 행사에서는 단순한 제품 설명이 아니라 <strong>문제 해결 중심의 사례 발표</strong>가 많았는데, 이 점이 특히 유익했다.<br />
어떤 회사는 AI를 통해 콜센터 자동화의 정확도를 높였고, 어떤 회사는 백오피스 문서 처리 시스템을 완전히 재구성했으며, 어떤 회사는 내부 지식 검색 시스템에 RAG를 도입하고 있었다.</p>

<hr />

<h2 id="4-행사장의-생생한-풍경">4. 행사장의 생생한 풍경</h2>

<p><img src="/assets/images/post_img/IMG_4649.JPG" alt="행사장소 목록" /><br />
<img src="/assets/images/post_img/IMG_4650.JPG" alt="Hall B의 위치" /></p>

<p>Hall B를 중심으로 세션이 배치되었고, 부스와 키노트 공간이 유기적으로 연결되어 있어 관람 동선이 편리했다.<br />
특히 Keynote Stage 옆 부스들에서는 생성형 AI, 보안, DevOps, Sustainability 관련 기술 시연이 이뤄졌고, <strong>데모를 기반으로 직접 묻고 듣는 공간</strong>으로 적극 활용되었다.</p>

<p>전시 구역에서 가장 많은 주목을 받은 기술은 단연 AI 기반 문서 요약, 이미지 생성, 코딩 보조 기능이었다. Bedrock 기반 모델과 파트너 모델들에 대한 체험형 시연도 관람객들의 발걸음을 멈추게 했다.</p>

<hr />

<h2 id="5-현장에서-느낀-세-가지">5. 현장에서 느낀 세 가지</h2>

<p>이번 AWS Summit을 통해 얻은 핵심 인사이트는 다음과 같다.</p>

<ol>
  <li><strong>AI는 더 이상 ‘기술’이 아니라 ‘기반’이다</strong>
    <ul>
      <li>단순한 도입 단계를 넘어서 이제는 <strong>운영 최적화와 비용 관리까지 포함된 실전 전개 단계</strong>로 넘어가고 있다.</li>
    </ul>
  </li>
  <li><strong>기술 친화도는 상상 이상으로 높아졌다</strong>
    <ul>
      <li>부스를 방문한 많은 이들이 AI/ML 관련 용어와 개념에 익숙했고, <strong>이미 파일럿을 진행 중이거나 도입을 검토 중</strong>인 경우가 많았다.</li>
    </ul>
  </li>
  <li><strong>AWS는 이제 ‘기술’을 팔지 않는다. ‘경험’과 ‘성공 시나리오’를 판다.</strong>
    <ul>
      <li>모든 세션, 부스, 키노트에서 공통적으로 느낀 점은 <strong>문제 중심의 접근</strong>과 <strong>고객 사례 중심의 설득</strong>이었다. 단순한 기능 설명보다 “우리는 이 문제를 이렇게 해결했다”는 서사가 강력한 메시지를 전달했다.</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="6-마치며">6. 마치며</h2>

<p>AWS Summit은 매년 열리지만, 올해처럼 메시지가 강하고 방향이 명확했던 해는 드물었다.<br />
특히 생성형 AI에 대한 AWS의 접근 방식은 단순한 추격자라기보다 <strong>생태계를 설계하는 메이커</strong>의 시선이었다.</p>

<p>클라우드 기술을 뛰어넘어 <strong>AI 기반 기업 운영을 고민하는 조직</strong>이라면, 이 서밋은 기술 쇼케이스를 넘어 <strong>비즈니스 전략을 재정비하는 계기</strong>가 되었을 것이다.</p>

<hr />

<blockquote>
  <p>“기술은 툴이 아니라 방향이다.<br />
AWS는 이번 서밋에서 그 방향을 명확하게 보여줬다.”</p>
</blockquote>]]></content><author><name>Your Name</name></author><category term="cloud" /><category term="AWS" /><category term="2025" /><category term="Summit" /><category term="코엑스" /><summary type="html"><![CDATA[AWS는 어떤 것을 밀고 있나?]]></summary></entry></feed>