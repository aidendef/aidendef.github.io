<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://aidendef.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://aidendef.github.io//" rel="alternate" type="text/html" /><updated>2025-06-25T08:44:38+00:00</updated><id>https://aidendef.github.io//feed.xml</id><title type="html">Aiden의 든든한 Blog</title><subtitle>Aiden&apos;s website.</subtitle><author><name>Your Name</name></author><entry><title type="html">AI 완전 자동화? 절반은 원하지 않는다 - 우리가 진짜 준비해야 할 역량</title><link href="https://aidendef.github.io//ai/AI-%EC%99%84%EC%A0%84-%EC%9E%90%EB%8F%99%ED%99%94-%EC%A0%88%EB%B0%98%EC%9D%80-%EC%9B%90%ED%95%98%EC%A7%80-%EC%95%8A%EB%8A%94%EB%8B%A4-%EC%9A%B0%EB%A6%AC%EA%B0%80-%EC%A7%84%EC%A7%9C-%EC%A4%80%EB%B9%84%ED%95%B4%EC%95%BC-%ED%95%A0-%EC%97%AD%EB%9F%89/" rel="alternate" type="text/html" title="AI 완전 자동화? 절반은 원하지 않는다 - 우리가 진짜 준비해야 할 역량" /><published>2025-06-24T15:08:00+00:00</published><updated>2025-06-24T15:08:00+00:00</updated><id>https://aidendef.github.io//ai/AI%20%EC%99%84%EC%A0%84%20%EC%9E%90%EB%8F%99%ED%99%94?%20%EC%A0%88%EB%B0%98%EC%9D%80%20%EC%9B%90%ED%95%98%EC%A7%80%20%EC%95%8A%EB%8A%94%EB%8B%A4%20-%20%EC%9A%B0%EB%A6%AC%EA%B0%80%20%EC%A7%84%EC%A7%9C%20%EC%A4%80%EB%B9%84%ED%95%B4%EC%95%BC%20%ED%95%A0%20%EC%97%AD%EB%9F%89</id><content type="html" xml:base="https://aidendef.github.io//ai/AI-%EC%99%84%EC%A0%84-%EC%9E%90%EB%8F%99%ED%99%94-%EC%A0%88%EB%B0%98%EC%9D%80-%EC%9B%90%ED%95%98%EC%A7%80-%EC%95%8A%EB%8A%94%EB%8B%A4-%EC%9A%B0%EB%A6%AC%EA%B0%80-%EC%A7%84%EC%A7%9C-%EC%A4%80%EB%B9%84%ED%95%B4%EC%95%BC-%ED%95%A0-%EC%97%AD%EB%9F%89/"><![CDATA[<h2 id="1-왜-이-논문을-알아야하나-얼마나-중요한가">1. 왜 이 논문을 알아야하나? 얼마나 중요한가?</h2>

<p>Future of Work with AI Agents 라는 논문을 읽고 아래 간략하게 작성을 진행할 것이다. 긴글을 읽기 앞서 왜 우리는 이 글을 봐야하는지 설명을 진행할 것이다.</p>

<p><img src="/assets/images/post_img/Future_of_Work.png" alt="future" /></p>

<p><strong>AI가 인간 노동을 대체할 것이라는 통념의 재검토</strong></p>

<p>최근 AI, 특히 생성형 AI와 에이전트 시스템의 발전은 “AI가 인간의 일을 모두 대체할 것이다”라는 막연한 두려움을 확대시키고 있다. 이런 담론은 기술 개발자, 정책 결정자, 기업 경영자, 일반 대중 모두에게 영향을 미친다. 그러나 이러한 단순한 대체 논리는 현실을 충분히 반영하지 못한다.</p>

<p><strong>AI 개발자의 시각과 현장 노동자의 현실 간 간극</strong></p>

<p>기존 연구와 기술 개발은 주로 ‘기술이 무엇을 할 수 있는가’에 집중되어 있다. 이 과정에서 실제 업무를 수행하는 현장 노동자의 ‘원하는 바’는 상대적으로 소외되어 왔다. 즉, 기술적 가능성과 사회적 수용성 사이의 균형을 고려한 연구가 부족했다.</p>

<p><strong>이 연구의 새로운 접근: 인간 중심, 작업 단위 중심, 이중 시각</strong></p>

<p>스탠포드의 본 연구는 다음 세 가지 점에서 기존 연구와 차별화된다:</p>

<ul>
  <li>
    <p><strong>노동자 중심의 목소리 수집:</strong> 1,500명의 현장 노동자를 직접 인터뷰하여 ‘어떤 작업을 AI가 도와주길 원하는가’를 물었다.</p>
  </li>
  <li>
    <p><strong>세부 작업(Task) 단위 분석:</strong> 직업 전체가 아닌 개별 작업 단위에서 AI 자동화 및 보조 가능성을 정밀하게 평가.</p>
  </li>
  <li>
    <p><strong>AI 전문가 평가 병행:</strong> 노동자 시각과 AI 전문가의 기술적 평가를 함께 수집하여 두 시각의 차이를 비교 분석.</p>
  </li>
</ul>

<p><strong>왜 지금 이 연구가 필요한가?</strong></p>

<ul>
  <li>
    <p>AI 기술이 실질적으로 현장에 투입되기 시작하는 시점에 도달했기 때문.</p>
  </li>
  <li>
    <p>AI가 단순 대체가 아닌 <strong>‘협력적 파트너십’</strong> 으로 작동할 수 있는 가능성을 검증해야 하기 때문.</p>
  </li>
  <li>
    <p>향후 교육, 직업 훈련, 정책 수립, 기술 개발 방향성을 설정하는데 구체적 데이터 기반이 부족했기 때문.</p>
  </li>
</ul>

<p>따라서 이 연구는 단순히 AI 기술의 성능을 평가하는 것이 아니라, <strong>“AI는 어떤 방식으로 인간과 일할 때 사회적으로 수용 가능하고, 더 나은 성과를 낼 수 있는가”</strong> 라는 본질적 질문을 다룬다.</p>

<h2 id="2-연구-개요">2. 연구 개요</h2>

<p><img src="/assets/images/post_img/overview.png" alt="overview" /></p>

<p><strong>연구 목적</strong></p>

<p>이 연구의 핵심 목적은 단순히 “AI가 무엇을 할 수 있는가?”가 아니라 <strong>“사람들은 AI가 무엇을 해주길 원하는가?”</strong> 를 정량적으로 파악하는 것이다. 이를 위해 연구진은 다음 두 가지 관점을 통합해서 살펴본다:</p>

<ul>
  <li>
    <p><strong>노동자의 희망 (Desire)</strong></p>
  </li>
  <li>
    <p><strong>기술적 가능성 (Capability)</strong></p>
  </li>
</ul>

<p>이 두 가지를 결합하여 실제 사회 현장에서 AI의 도입 가능성과 한계를 분석한다.</p>

<hr />

<p><strong>연구 설계</strong></p>

<ol>
  <li>
    <p><strong>대상: 104개 직업군, 844개 작업(Task)</strong><br />
미국 노동부 O*NET 데이터베이스를 기반으로 실제 업무에서 수행되는 세부 작업 단위로 분해하여 조사 수행.</p>
  </li>
  <li>
    <p><strong>노동자 인터뷰 (1,500명 참여):</strong><br />
각 작업에 대해 다음 두 가지를 평가:</p>

    <ul>
      <li>
        <p>이 작업을 AI가 완전히 대신해주길 원하는가? (자동화 희망도)</p>
      </li>
      <li>
        <p>이 작업에서 어느 정도 인간의 주도성이 필요한가? (Human Agency Scale, HAS)</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>AI 전문가 평가 (52명 참여):</strong><br />
동일 작업에 대해 기술적 관점에서:</p>

    <ul>
      <li>
        <p>현재 AI가 이 작업을 어느 정도 자동화할 수 있는가?</p>
      </li>
      <li>
        <p>어느 정도 인간의 주도성이 기술적으로 필요한가?</p>
      </li>
    </ul>
  </li>
</ol>

<hr />

<p><img src="/assets/images/post_img/HAS.png" alt="HAS" /></p>

<p><strong>Human Agency Scale (HAS) 도입</strong></p>

<p>연구진은 단순히 “자동화 가능/불가능”으로 나누는 이분법을 넘어, <strong>인간과 AI의 협력 정도</strong>를 5단계 척도로 구분:</p>

<ul>
  <li>
    <p>H1: 완전 자동 (AI 혼자 수행)</p>
  </li>
  <li>
    <p>H2: 거의 자동 (소량의 인간 개입 필요)</p>
  </li>
  <li>
    <p>H3: 인간과 AI가 동등한 파트너로 협업</p>
  </li>
  <li>
    <p>H4: AI는 보조 역할, 인간이 주도</p>
  </li>
  <li>
    <p>H5: AI 없이 인간이 필수로 수행</p>
  </li>
</ul>

<p>이 <strong>HAS 척도</strong>는 앞으로의 AI 시스템 개발에서 ‘얼마나 인간 중심으로 설계할 것인가’를 판단하는 중요한 기준이 된다.</p>

<hr />

<p><img src="/assets/images/post_img/workbank.png" alt="workbank" /></p>

<p><strong>WORKBank 데이터베이스 구축</strong></p>

<p>이 모든 평가 결과는 <strong>WORKBank (Worker Outlook &amp; Readiness Knowledge Bank)</strong> 라는 데이터베이스로 구축되었으며, 이는 최초의 대규모 인간 중심 AI 자동화/협업 평가 데이터로서 매우 중요한 기초 자료가 된다.</p>

<h2 id="3-노동자들의-ai-자동화에-대한-인식">3. 노동자들의 AI 자동화에 대한 인식</h2>

<p><img src="/assets/images/post_img/domain_workers.png" alt="domain_workers" /></p>

<p><strong>노동자들은 AI 자동화를 얼마나 원하고 있을까?</strong></p>

<p>연구 결과, 전체 작업 중 <strong>46.1%</strong> 에 대해 노동자들은 <strong>AI가 자동화해 주길 원한다</strong>고 응답했다.<br />
즉, 절반 정도의 작업에서는 노동자들이 AI가 일정 부분 업무를 대신해주길 희망하고 있다.</p>

<p>그러나 이는 단순한 ‘대체 희망’이 아니다. 그 속내는 다음과 같다:</p>

<ul>
  <li>
    <p><strong>주요 동기:</strong></p>

    <ul>
      <li>
        <p>반복적이고 지루한 작업을 줄이고</p>
      </li>
      <li>
        <p>더 가치 있는 일, 창의적이거나 고부가가치 작업에 집중하고 싶다는 것이다.</p>
      </li>
      <li>
        <p>가장 많이 선택된 이유는 <strong>“내 시간을 고부가가치 작업에 쓰고 싶다” (69.4%)</strong></p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>반복성, 스트레스, 품질 향상 등도 주요 이유:</strong></p>

    <ul>
      <li>
        <p>지루하거나 반복적인 업무 (46.6%)</p>
      </li>
      <li>
        <p>정신적으로 소모적인 업무 (25.5%)</p>
      </li>
      <li>
        <p>AI가 하면 더 높은 품질을 낼 수 있을 것 같은 업무 (46.6%)</p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<p><img src="/assets/images/post_img/domain_workers1.png" alt="domain_workers1" /></p>

<p><strong>분야별 차이도 뚜렷하다</strong></p>

<ul>
  <li>
    <p><strong>AI 자동화를 가장 많이 원하는 직군:</strong></p>

    <ul>
      <li>
        <p>세무, 행정, 시간관리 등 비교적 규칙적이고 반복성이 높은 업무</p>
      </li>
      <li>
        <p>예: 세무사 - 고객과의 약속 일정 잡기 (Aw = 5.00)</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>자동화 희망이 가장 낮은 직군:</strong></p>

    <ul>
      <li>
        <p>예술, 디자인, 미디어 등 창의성이 중요한 직종</p>
      </li>
      <li>
        <p>예: 에디터, 아트 디렉터, 비디오게임 디자이너 등 (Aw 평균 1.5~1.6)</p>
      </li>
    </ul>
  </li>
</ul>

<p>노동자들은 <strong>‘창작 자체’를 AI가 대신하는 것에 대해 거부감</strong>을 보였다.<br />
대신 “AI가 반복적인 워크플로우는 도와주되, 창작은 내가 한다”는 입장이 많았다.</p>

<hr />

<p><strong>노동자의 우려도 존재한다</strong></p>

<p>AI 자동화에 대한 저항감이나 불안 요소로는 다음이 주요하게 나타났다:</p>

<ol>
  <li>
    <p><strong>AI 시스템의 정확성, 신뢰성 부족 (45.0%)</strong></p>
  </li>
  <li>
    <p><strong>직업 상실에 대한 두려움 (23.0%)</strong></p>
  </li>
  <li>
    <p><strong>인간만이 가진 감정적 능력 부재 (16.3%)</strong></p>
  </li>
</ol>

<p>특히 ‘예술·디자인·미디어’ 분야에서는 AI가 ‘창작 감각’, ‘예술적 컨트롤’, ‘인간의 직관’을 대체하기 어렵다고 인식하고 있었다.</p>

<hr />

<p><strong>현재 AI 사용 패턴과 노동자 희망의 불일치</strong></p>

<p>재미있는 점은, 실제 AI 도구 활용 데이터(Claude.ai 사용 로그)와 비교했을 때:</p>

<ul>
  <li>
    <p><strong>노동자가 자동화를 가장 희망하는 작업들이 실제 AI 활용도는 낮다.</strong></p>
  </li>
  <li>
    <p>즉, AI 도입이 기술적 가능성보다 <strong>사회적 수요를 제대로 반영하지 못하고 있다</strong>는 점을 시사한다.</p>
  </li>
</ul>

<hr />

<p>핵심 메시지:<br />
<strong>노동자들은 “AI가 내 일을 빼앗는 것”보다는 “AI가 내 일을 도와주는 것”을 원한다.</strong><br />
<strong>특히 반복적·지루한 작업을 AI에게 넘기고, 더 가치 있는 일에 집중하고 싶어 한다.</strong></p>

<h2 id="4-desire-capability-landscape-욕구와-기술력의-불일치">4. Desire-Capability Landscape: 욕구와 기술력의 불일치</h2>

<p><img src="/assets/images/post_img/Integrating_worker_and_AI_expert_perspectives.png" alt="Integrating_worker_and_AI_expert_perspectives" /></p>

<p><strong>AI 도입 가능성을 4개의 구역으로 시각화</strong></p>

<p>이 연구의 핵심적인 분석은 노동자의 자동화 욕구와 AI 전문가의 기술적 가능성을 <strong>2축으로 교차 분석</strong>한 것이다.<br />
이를 통해 각 작업(task)을 다음 4가지 구역으로 분류했다:</p>

<hr />

<p><strong>① Green Light Zone (높은 욕구 + 높은 기술 가능성)</strong></p>

<ul>
  <li>
    <p>AI 도입의 ‘바로 실행 가능한’ 영역</p>
  </li>
  <li>
    <p>노동자도 AI가 해주길 바라고, 기술적으로도 가능한 작업</p>
  </li>
  <li>
    <p>반복성 높고 규칙적인 업무 다수 포함</p>
  </li>
  <li>
    <p>예: 일정 예약, 품질 관리 보고서 확인 등</p>
  </li>
</ul>

<hr />

<p><strong>② Red Light Zone (낮은 욕구 + 높은 기술 가능성)</strong></p>

<ul>
  <li>
    <p>기술적으로는 충분히 가능하지만,</p>
  </li>
  <li>
    <p>노동자들은 AI가 대신하길 원하지 않는 영역</p>
  </li>
  <li>
    <p>예: IT 네트워크 조사, 잠재 공급업체 조사 등</p>
  </li>
  <li>
    <p>이 영역에선 AI 도입 시 현장의 저항 가능성이 존재</p>
  </li>
</ul>

<hr />

<p><strong>③ R&amp;D Opportunity Zone (높은 욕구 + 낮은 기술 가능성)</strong></p>

<ul>
  <li>
    <p>노동자들은 AI가 해주길 원하지만,</p>
  </li>
  <li>
    <p>아직 기술적으로 부족한 영역 → AI 연구개발 우선 대상</p>
  </li>
  <li>
    <p>예: 게임 프로토타입 개발 일정 조율, 연구 예산 배분 조정 등</p>
  </li>
  <li>
    <p>복잡한 의사결정, 예측 불확실성이 큰 작업 포함</p>
  </li>
</ul>

<hr />

<p><strong>④ Low Priority Zone (낮은 욕구 + 낮은 기술 가능성)</strong></p>

<ul>
  <li>
    <p>노동자도 별로 AI 도움을 원하지 않고, 기술적으로도 어려운 영역</p>
  </li>
  <li>
    <p>현재로선 AI 개발 우선순위가 낮은 영역</p>
  </li>
</ul>

<hr />

<p><strong>데이터 상에서 관찰된 경향</strong></p>

<ul>
  <li>
    <p><strong>노동자의 욕구와 기술 가능성은 완벽히 일치하지 않는다</strong> (상관계수 0.17, 매우 낮음)</p>
  </li>
  <li>
    <p>사람들이 즐기거나 자부심을 느끼는 업무일수록 자동화를 덜 원한다.</p>
  </li>
  <li>
    <p>반복적 업무에서 자동화 욕구가 집중되는 경향</p>
  </li>
</ul>

<hr />

<p><strong>현재 투자 및 연구개발의 불균형</strong></p>

<ul>
  <li>
    <p>현재 스타트업 투자(Y Combinator 기반 분석)는 <strong>Green Light나 R&amp;D Opportunity Zone보다 Red Light Zone에도 상당히 집중되어 있음</strong>.</p>
  </li>
  <li>
    <p>연구논문(arXiv 기반 분석)은 상대적으로 <strong>R&amp;D Opportunity Zone에 더 집중</strong>되긴 하지만,</p>
  </li>
  <li>
    <p>여전히 소프트웨어, 컴퓨터공학 중심으로 한정되어 있음.</p>
  </li>
</ul>

<hr />

<p><strong>핵심 시사점</strong></p>

<ul>
  <li>
    <p>AI 도입을 논할 때 단순히 기술적 가능성만 볼 게 아니라 <strong>사회적 수용성 (노동자의 욕구)</strong>를 반드시 함께 고려해야 한다.</p>
  </li>
  <li>
    <p><strong>AI의 ‘사회적 합의 기반 도입 로드맵’을 설계해야 하는 이유</strong>가 여기에 있다.</p>
  </li>
</ul>

<h2 id="5-human-agency-scale-has-인간과-ai의-협업-수준">5. Human Agency Scale (HAS): 인간과 AI의 협업 수준</h2>

<p><img src="/assets/images/post_img/Distributions_on_the_Human_Agency_Scale.png" alt="Distributions_on_the_Human_Agency_Scale" /></p>

<p><strong>단순 자동화를 넘어 협업을 본격적으로 측정하다</strong></p>

<p>이 연구의 또 다른 핵심 기여는 <strong>Human Agency Scale (HAS)</strong> 개념의 도입이다.<br />
기존에는 AI 자동화를 <strong>할 수 있느냐/없느냐</strong>만 따졌다면,<br />
이제는 <strong>얼마나 인간이 주도적으로 개입해야 하는가</strong>를 체계적으로 계량화했다.</p>

<hr />

<p><strong>Human Agency Scale (HAS) 5단계 정의</strong></p>

<table>
  <thead>
    <tr>
      <th>HAS</th>
      <th>설명</th>
      <th>대표 작업 예시</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>H1</td>
      <td>AI가 완전히 독자 수행</td>
      <td>단순 데이터 입력, 반복 보고서 생성</td>
    </tr>
    <tr>
      <td>H2</td>
      <td>소량의 인간 개입</td>
      <td>네트워크 보고서 수집, 옵션 거래 전략 개발</td>
    </tr>
    <tr>
      <td>H3</td>
      <td>인간-AI 동등한 파트너십</td>
      <td>연구 데이터 해석, 코어 게임 기획</td>
    </tr>
    <tr>
      <td>H4</td>
      <td>인간이 주도, AI는 보조</td>
      <td>재무 기획, 예산 배분 조정</td>
    </tr>
    <tr>
      <td>H5</td>
      <td>인간 없이는 불가능</td>
      <td>디자인 컨셉 제작, 고차원적 협상</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>노동자와 전문가 간 HAS 인식 차이</strong></p>

<ul>
  <li>
    <p>노동자들은 대체로 <strong>더 높은 인간 주도성(H3~H5)</strong> 을 선호</p>
  </li>
  <li>
    <p>전문가들은 기술적 가능성을 기준으로 <strong>H1~H2</strong>에서도 충분하다고 평가하는 경우 다수</p>
  </li>
</ul>

<blockquote>
  <p>노동자 입장: “내가 직접 해야 마음이 놓인다.”<br />
전문가 입장: “AI가 할 수 있는데 굳이 사람이 필요할까?”</p>
</blockquote>

<p>이 간극은 향후 AI 도입 과정에서 <strong>사회적 마찰 가능성</strong>을 예고한다.</p>

<hr />

<p><strong>주요 통계 요약</strong></p>

<ul>
  <li>
    <p>전체 작업 중 <strong>45.2%에서 노동자가 H3 (AI와 동등한 협력) 수준을 선호</strong></p>
  </li>
  <li>
    <p>완전 자동화(H1) 선호는 1.9%에 불과</p>
  </li>
  <li>
    <p>거의 모든 직업군에서 <strong>협력 중심(Augmentation 중심)의 HAS 분포</strong>가 관찰됨 (U자형 경향)</p>
  </li>
</ul>

<hr />

<p><strong>협력 형태에 대한 노동자의 구체적 기대</strong></p>

<ul>
  <li>
    <p>AI가 역할 기반 보조자(Role-based Assistant)로 동작하길 기대</p>
  </li>
  <li>
    <p>“AI는 반복적 품질검사 자동화, 데이터 정제 제안, 일정 일부 관리 등을 맡아주고<br />
<strong>최종 결정과 창의적 작업은 내가 맡겠다</strong>“는 입장이 지배적</p>
  </li>
</ul>

<hr />

<p><strong>HAS가 AI 시스템 개발 방향성을 바꾼다</strong></p>

<ul>
  <li>
    <p>H1~H2 작업: 기술 중심의 완전 자동화 목표 적합</p>
  </li>
  <li>
    <p>H3~H5 작업: 인간-AI 간 <strong>협력 인터페이스, 조율, 신뢰 형성 메커니즘</strong>이 중요</p>
  </li>
</ul>

<p>AI 개발자는 단순 기능 구현이 아니라<br />
<strong>‘사람과 AI가 팀으로 일하는 시스템’을 설계</strong>해야 하는 시대에 진입하고 있음을 보여준다.</p>

<h2 id="6-직업별-협업-가능성-사례">6. 직업별 협업 가능성 사례</h2>

<p><img src="/assets/images/post_img/Comparing_skill_rankings.png" alt="Comparing_skill_rankings" /></p>

<p><strong>직업별로 AI 도입 가능성과 협업 방식이 크게 다르다</strong></p>

<p>HAS 스펙트럼을 기반으로 각 직업군의 특징을 분석하면,<br />
<strong>어디에서 AI 협력이 현실적이고, 어디에서는 어려운지</strong> 더 구체적인 사례를 확인할 수 있다.</p>

<hr />

<h3 id="-ai가-대체하기-쉬운-작업-h1h2-중심-직업군">① AI가 대체하기 쉬운 작업 (H1~H2 중심 직업군)</h3>

<ul>
  <li>
    <p><strong>컴퓨터 프로그래머</strong></p>

    <ul>
      <li>
        <p>기존 프로그램 유지보수, 단순 코드 리팩토링, 데이터 입력</p>
      </li>
      <li>
        <p>반복성이 높고 규칙이 명확한 작업이 많음</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>교정·편집자 (Proofreader)</strong></p>

    <ul>
      <li>문장 교정, 맞춤법 수정 등 규칙 기반의 작업 가능</li>
    </ul>
  </li>
  <li>
    <p><strong>여행사·발권 직원</strong></p>

    <ul>
      <li>항공권 발권, 수화물 추적 등 표준화된 절차 중심 작업</li>
    </ul>
  </li>
</ul>

<p>이 영역에서는 <strong>완전 자동화(AI 주도형)</strong>가 상대적으로 사회적 저항이 적을 수 있다.</p>

<hr />

<h3 id="-인간-중심성이-필요한-작업-h3h5-중심-직업군">② 인간 중심성이 필요한 작업 (H3~H5 중심 직업군)</h3>

<ul>
  <li>
    <p><strong>디자이너·아트 디렉터</strong></p>

    <ul>
      <li>
        <p>창의적 기획, 디자인 감각, 고객 피드백 반영 등</p>
      </li>
      <li>
        <p>감성적 요소와 맥락 이해가 중요한 작업</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>비디오 게임 디자이너</strong></p>

    <ul>
      <li>
        <p>제작 스텝과의 협업을 통한 일정 조정, 아이디어 조율</p>
      </li>
      <li>
        <p>변동성이 크고 인간 간 협상이 필수</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>과학자·연구 관리자</strong></p>

    <ul>
      <li>
        <p>연구 예산 배분, 프로젝트 우선순위 결정 등</p>
      </li>
      <li>
        <p>정량적 계산보다 장기적 연구 방향성 설정 필요</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>교육·트레이닝 담당자</strong></p>

    <ul>
      <li>
        <p>타인에게 가르치고 동기부여하는 활동</p>
      </li>
      <li>
        <p>대인관계, 피드백, 감정적 케어 요소가 중심</p>
      </li>
    </ul>
  </li>
</ul>

<p>이 영역은 <strong>AI가 보조자로 존재하되, 인간의 최종 결정과 조정이 본질적으로 필요한</strong> 분야다.</p>

<hr />

<h3 id="-ai와-협업-형태가-가장-이상적인-영역-h3-중심-직업군">③ AI와 협업 형태가 가장 이상적인 영역 (H3 중심 직업군)</h3>

<ul>
  <li>
    <p><strong>품질관리, 일정관리, 조직 조율, 중간관리</strong></p>

    <ul>
      <li>
        <p>AI가 실시간 데이터 분석·모니터링을 수행하고</p>
      </li>
      <li>
        <p>사람은 그 데이터를 기반으로 의사결정 및 조율 담당</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>의료·상담·코칭</strong></p>

    <ul>
      <li>
        <p>AI가 진단 보조, 정보 요약, 사례 추천을 제공</p>
      </li>
      <li>
        <p>인간이 최종 상담, 공감, 개별 케이스 맞춤 처리</p>
      </li>
    </ul>
  </li>
</ul>

<hr />

<p><strong>핵심 요점</strong></p>

<ul>
  <li>
    <p>AI 도입은 단순 기술력 문제가 아니라 <strong>업무 성격 자체의 차이에 따라 협업 설계가 달라진다</strong>.</p>
  </li>
  <li>
    <p><strong>정보 전달, 반복 작업 → AI 중심</strong></p>
  </li>
  <li>
    <p><strong>의사결정, 창의적 조율, 감정 노동 → 인간 중심</strong></p>
  </li>
</ul>

<p>결국 각 직무마다 <strong>“AI와 인간의 협업 비율을 어떻게 설정할 것인가”</strong> 가 핵심이 된다.</p>

<h2 id="7-ai-도입이-가져올-미래-핵심-역량-변화">7. AI 도입이 가져올 미래 핵심 역량 변화</h2>

<p><strong>AI 도입은 단순히 업무만 바꾸는 것이 아니라, ‘인간에게 요구되는 역량’ 자체를 재편하고 있다.</strong></p>

<p>본 연구에서는 AI 도입이 진행될수록 <strong>어떤 인간 역량이 상대적으로 더 중요해지고, 무엇이 덜 중요해지는지</strong>를 구체적으로 정량화했다.</p>

<p>이를 위해:</p>

<ul>
  <li>
    <p>각 작업(task)을 <strong>O*NET의 직무 스킬군</strong>으로 연결</p>
  </li>
  <li>
    <p>각 스킬별 평균 임금 (현재 시장가치)과</p>
  </li>
  <li>
    <p>전문가 평가 기준 HAS (향후 인간 개입 수준) 분석을 함께 비교</p>
  </li>
</ul>

<hr />

<h3 id="-상대적-가치가-줄어드는-역량-정보처리-중심-스킬">① 상대적 가치가 줄어드는 역량: 정보처리 중심 스킬</h3>

<ul>
  <li>
    <p><strong>데이터 분석 / 정보 해석 / 정보 업데이트</strong></p>
  </li>
  <li>
    <p>현재까지는 고임금 핵심 스킬이었지만,</p>
  </li>
  <li>
    <p>AI가 이 영역을 빠르게 대체·보조할 수 있음</p>
  </li>
  <li>
    <p>예: 데이터 수집, 수치 계산, 패턴 인식 등</p>
  </li>
</ul>

<p><strong>핵심 메시지:</strong><br />
‘정형화된 정보 처리’는 점점 더 AI에 의해 수행될 가능성이 커진다.</p>

<hr />

<h3 id="-상대적-가치가-높아지는-역량-대인관계조직관리-중심-스킬">② 상대적 가치가 높아지는 역량: 대인관계·조직관리 중심 스킬</h3>

<ul>
  <li>
    <p><strong>다른 사람을 가르치고 훈련하기 (Training, Teaching Others)</strong></p>
  </li>
  <li>
    <p><strong>의사소통 및 관계 형성 (Communicating, Establishing Relationships)</strong></p>
  </li>
  <li>
    <p><strong>결정 내리기 및 문제 해결 (Decision Making, Problem Solving)</strong></p>
  </li>
  <li>
    <p><strong>조직, 기획, 우선순위 설정 (Organizing, Planning, Prioritizing Work)</strong></p>
  </li>
</ul>

<p>이러한 스킬들은 현재 상대적으로 저평가(임금 낮음) 되어 있지만,<br />
AI 도입이 확대될수록 오히려 더 중요한 차별화 요소로 부상 중이다.</p>

<p><strong>핵심 메시지:</strong><br />
‘사람 중심의 조율·교육·관계 유지 능력’이 인간 고유 역량으로 더욱 부각된다.</p>

<hr />

<h3 id="-공통-특징-ai가-어려워하는-스킬은-불확실성과-사람이-중심">③ 공통 특징: AI가 어려워하는 스킬은 “불확실성과 사람”이 중심</h3>

<ul>
  <li>
    <p><strong>정해진 답이 없는 문제</strong></p>
  </li>
  <li>
    <p><strong>협상, 감정적 공감, 실시간 피드백</strong></p>
  </li>
  <li>
    <p><strong>동기부여, 관계 유지, 팀워크 조율</strong> 등</p>
  </li>
</ul>

<p>이는 <strong>AI의 한계지점이자, 인간이 유지할 경쟁력의 핵심 영역</strong>임을 보여준다.</p>

<hr />

<h3 id="정리-ai-시대의-인간-역량-변화-요약">정리: AI 시대의 인간 역량 변화 요약</h3>

<table>
  <thead>
    <tr>
      <th>줄어드는 영역</th>
      <th>부상하는 영역</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>정형 정보처리, 분석</td>
      <td>대인관계, 의사소통</td>
    </tr>
    <tr>
      <td>반복적 수작업</td>
      <td>조직관리, 의사결정</td>
    </tr>
    <tr>
      <td>기계학습이 잘하는 예측</td>
      <td>맥락 기반 창의적 조정</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>이 변화는 교육·직업훈련·정책 모두에 큰 시사점을 준다.</strong><br />
향후 인재 양성 방향도 <strong>“AI가 할 수 없는 영역을 키우는 교육”</strong> 으로 재편될 필요가 있음을 시사한다.</p>

<h2 id="8-시사점과-결론">8. 시사점과 결론</h2>

<p><strong>AI 기술 개발자에게 주는 메시지</strong></p>

<ul>
  <li>
    <p>기술 개발은 단순히 <strong>“AI가 얼마나 똑똑해졌나”</strong> 가 아니라</p>
  </li>
  <li>
    <p><strong>“누구를 위해, 어떤 문제를 해결하기 위해 만드는가”</strong> 가 핵심이 되어야 한다.</p>
  </li>
  <li>
    <p><strong>AI 성능 벤치마크 (LLM 정확도, 에이전트 성능 등) 중심의 개발만으로는 부족하다.</strong></p>
  </li>
  <li>
    <p>HAS 프레임워크처럼 <strong>‘인간이 원하는 협력 방식’을 고려한 개발</strong>이 필요하다.</p>
  </li>
</ul>

<hr />

<p><strong>정책 결정자와 교육기관에게 주는 시사점</strong></p>

<ul>
  <li>
    <p>향후 교육과 직업훈련은 다음 영역에 집중해야 한다:</p>

    <ul>
      <li>
        <p>관계 형성, 협상, 공감 등 대인관계 역량</p>
      </li>
      <li>
        <p>조직 조정, 계획 수립, 의사결정 역량</p>
      </li>
      <li>
        <p>AI 협력 활용 역량 (AI 활용 Literacy)</p>
      </li>
    </ul>
  </li>
  <li>
    <p>기존 정보처리·분석 중심 교육 커리큘럼은<br />
<strong>AI 시대에 불충분해질 가능성이 있다.</strong></p>
  </li>
</ul>

<hr />

<p><strong>노동자·일반 직장인에게 주는 시사점</strong></p>

<ul>
  <li>
    <p>AI는 <strong>‘내 일을 빼앗는 존재’</strong> 라기보다는<br />
<strong>‘잘 활용하면 내 업무를 가치를 더 높여주는 협력 파트너’</strong> 로 접근해야 한다.</p>
  </li>
  <li>
    <p>반복적이고 지루한 작업을 AI에게 넘기고,<br />
인간은 <strong>창의성·조정·관계 중심 업무에 집중</strong>하는 전략적 업무 재편이 필요하다.</p>
  </li>
</ul>

<hr />

<p><strong>사회 전체에 주는 근본적 통찰</strong></p>

<ul>
  <li>
    <p>AI 도입은 <strong>“기술적 가능성 → 사회적 수용성”으로 이행되어야 한다.</strong></p>
  </li>
  <li>
    <p>노동자의 ‘주도성’을 유지하면서 협력 모델을 설계하는 것이 사회적 합의의 핵심</p>
  </li>
  <li>
    <p><strong>“AI의 발전 속도보다, 우리가 AI를 어떻게 사회에 통합할 것인가가 더 중요하다.”</strong></p>
  </li>
</ul>

<hr />

<p><strong>결론 요약</strong></p>

<ul>
  <li>
    <p>이 연구는 최초로 <strong>노동자 희망 vs 기술 가능성 vs 협업 모델</strong>을 통합적으로 정량 분석했다.</p>
  </li>
  <li>
    <p>AI 시대의 ‘협력 중심 작업 모델’ 설계는<br />
이제 단순한 선택이 아니라 <strong>AI 성공적 도입의 필수 요건</strong>이 되고 있다.</p>
  </li>
  <li>
    <p>앞으로의 AI 개발, 정책, 교육, 기업 전략 모두<br />
“AI와 인간의 이상적 협업 구도” 설계가 중심축이 되어야 한다.</p>
  </li>
</ul>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="Human-Centric AI" /><category term="AI Collaboration" /><category term="Future of Work" /><category term="Human Agency" /><category term="Augmentation over Automation" /><category term="Future of Work with AI Agents" /><summary type="html"><![CDATA[AI가 당신의 일을 뺏지 않는 이유: 스탠포드 대규모 연구가 밝힌 충격적 결과]]></summary></entry><entry><title type="html">나, 내 팀원이 가졌으면 하는 개발자 마인드</title><link href="https://aidendef.github.io//private/blog/%EA%B0%9C%EB%B0%9C%EC%9E%90_%EB%A7%88%EC%9D%B8%EB%93%9C-copy/" rel="alternate" type="text/html" title="나, 내 팀원이 가졌으면 하는 개발자 마인드" /><published>2025-05-27T15:08:00+00:00</published><updated>2025-05-27T15:08:00+00:00</updated><id>https://aidendef.github.io//private/blog/%EA%B0%9C%EB%B0%9C%EC%9E%90_%EB%A7%88%EC%9D%B8%EB%93%9C%20copy</id><content type="html" xml:base="https://aidendef.github.io//private/blog/%EA%B0%9C%EB%B0%9C%EC%9E%90_%EB%A7%88%EC%9D%B8%EB%93%9C-copy/"><![CDATA[<h2 id="개발자-마인드란">개발자 마인드란?</h2>
<p>사실 개발을 진행하면서 개발실력이 중요하지만 서로서로 의견을 소통하고 교류하는 것이 더 크다.</p>

<p>이럴때 우리는 어떤 마인드를 가지며 살아가야할까?</p>

<p>아래 다른 포스팅이나 유튜브 등의 글을 지속적으로 업데이트할 예정이다.</p>

<h2 id="링크-모음">링크 모음</h2>

<ul>
  <li><a href="https://toss.tech/article/8-writing-principles-of-toss">토스의 8가지 라이팅 원칙들</a></li>
  <li><a href="https://pm-developer-justdoit.tistory.com/304">주니어 개발자 마인드셋</a></li>
  <li><a href="https://platum.kr/archives/261482">생각과 손 사이의 거리</a></li>
</ul>]]></content><author><name>Your Name</name></author><category term="private" /><category term="blog" /><category term="Problem Framing" /><category term="junior" /><category term="developer" /><category term="pm" /><category term="writing" /><category term="toss" /><summary type="html"><![CDATA[개발자 마인드를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(8)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(8)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(8)" /><published>2025-05-26T15:08:00+00:00</published><updated>2025-05-26T15:08:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(8)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(8)/"><![CDATA[<h2 id="동적인-breakpoint">동적인 Breakpoint</h2>

<p>특정 단계에서 그래프를 멈추는 일반적인 방법으로 중단점을 다루었으며, 이를 통해 ‘승인’과 같은 사용 사례를 구현할 수 있습니다.</p>

<p>또한 그래프 상태를 편집하는 방법과 사람의 피드백을 도입하는 방법도 소개했습니다.</p>

<p>중단점은 개발자가 그래프를 컴파일하는 동안 특정 노드에 설정합니다.</p>

<p>하지만 때로는 그래프가 동적으로 중단되도록 하는 것이 유용할 때가 있습니다!</p>

<p>이것은 내부 중단점이며, NodeInterrupt를 사용하여 달성할 수 있습니다.</p>

<p>여기에는 몇 가지 구체적인 이점이 있습니다:</p>

<p>(1) 개발자가 정의한 로직에 따라 노드 내부에서 조건부로 수행할 수 있습니다.</p>

<p>(2) 사용자에게 인터럽트 이유를 전달할 수 있습니다(원하는 내용을 NodeInterrupt에 전달하여).</p>

<p>그러면, 다음 예제를 통해서 입력의 길이에 따라 NodeInterrupt가 발생하는 그래프를 만들어 보겠습니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display

from typing_extensions import TypedDict
from langgraph.checkpoint.memory import MemorySaver
from langgraph.errors import NodeInterrupt
from langgraph.graph import START, END, StateGraph

class State(TypedDict):
    input: str

def step_1(state: State) -&gt; State:
    print("---Step 1---")
    return state

def step_2(state: State) -&gt; State:
    # Let's optionally raise a NodeInterrupt if the length of the input is longer than 5 characters
    print("--Step 2 (before Node Interrupt)--")
    if len(state['input']) &gt; 5:
        raise NodeInterrupt(f"Received input that is longer than 5 characters: {state['input']}")
    
    print("---Step 2---")
    return state

def step_3(state: State) -&gt; State:
    print("---Step 3---")
    return state

builder = StateGraph(State)
builder.add_node("step_1", step_1)
builder.add_node("step_2", step_2)
builder.add_node("step_3", step_3)
builder.add_edge(START, "step_1")
builder.add_edge("step_1", "step_2")
builder.add_edge("step_2", "step_3")
builder.add_edge("step_3", END)

# Set up memory
memory = MemorySaver()

# Compile the graph with memory
graph = builder.compile(checkpointer=memory)

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>

<p><img src="/assets/images/post_img/langgraph8.png" alt="langgraph8" /></p>

<p>5자보다 긴 글자 입력으로 그래프를 실행해 보겠습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>initial_input = {"input": "hello world"}
thread_config = {"configurable": {"thread_id": "1"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread_config, stream_mode="values"):
    print(event)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'input': 'hello world'}
---Step 1---
{'input': 'hello world'}
--Step 2 (before Node Interrupt)--
</code></pre></div></div>
<p>이 시점에서 그래프 상태를 검사하면, step_2가 다음 노드라고 가리키고 있음을 알 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread_config)
print(state.next)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('step_2',)
</code></pre></div></div>
<p>상세내용을 확인해 보면, <code class="language-plaintext highlighter-rouge">Interrupt</code>가 상태로 기록된 것을 볼 수 있습니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(state.tasks)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(PregelTask(id='39005008-94cd-c3f2-e40e-638b2445966a', name='step_2', path=('__pregel_pull', 'step_2'), error=None, interrupts=(Interrupt(value='Received input that is longer than 5 characters: hello world', resumable=False, ns=None, when='during'),), state=None, result=None),)
</code></pre></div></div>
<p>중단점에서 그래프를 다시 시작할 수 있습니다.</p>

<p>하지만 이것은 동일한 노드를 다시 실행할 뿐입니다!</p>

<p>상태가 변경되지 않는 한 우리는 여기서 멈출 것입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread_config, stream_mode="values"):
    print(event)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'input': 'hello world'}
--Step 2 (before Node Interrupt)--
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread_config)
print(state.next)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('step_2',)
</code></pre></div></div>

<p>그래서 우리는 상태를 업데이트해서 이 상태를 벗어나게 할 것입니다.
이번에는 5자보다 적은 글자수를 입력하여 수행해 보입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.update_state(
    thread_config,
    {"input": "hi"},
)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'configurable': {'thread_id': '1',
  'checkpoint_ns': '',
  'checkpoint_id': '1eff4f97-39ca-67f8-8002-98b845337fa1'}}
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread_config, stream_mode="values"):
    print(event)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'input': 'hi'}
--Step 2 (before Node Interrupt)--
---Step 2---
{'input': 'hi'}
---Step 3---
{'input': 'hi'}
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread_config)
print(state.next)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>()
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[동적인 Breakpoint을 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(7)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(7)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(7)" /><published>2025-05-26T15:07:00+00:00</published><updated>2025-05-26T15:07:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(7)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(7)/"><![CDATA[<h2 id="human-in-the-loop-변경">Human in the Loop 변경</h2>
<p>중단점이 사용자 승인을 지원하는 방법을 보여드렸지만 그래프가 중단된 후 그래프 상태를 수정하는 방법에 대해서는 아직 설명드리지 않았습니다.</p>

<p>이제 그래프 상태를 직접 편집하고 사람의 피드백을 입력하는 방법을 보여드리겠습니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>
<h2 id="상태-수정">상태 수정</h2>

<p>이전에는 중단점을 도입했습니다.</p>

<p>그래프를 중단하고 다음 노드를 실행하기 전에 사용자의 승인을 기다리는 데 사용했습니다.</p>

<p>하지만 중단점은 그래프 상태를 수정할 수 있는 기회이기도 합니다.</p>

<p>어시스턴트 노드 앞에 중단점이 있는 에이전트를 설정해 보겠습니다.</p>

<h2 id="툴-선언">툴 선언</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]
llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode

from langchain_core.messages import HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine the control flow
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")

memory = MemorySaver()
graph = builder.compile(interrupt_before=["assistant"], checkpointer=memory)

# Show
display(Image(graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>

<p><img src="/assets/images/post_img/langgraph7.png" alt="langgraph7" /></p>

<p>수행해 봅시다.</p>

<p>채팅 모델이 응답하기 전에 그래프가 중단된 것을 볼 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Input
initial_input = {"messages": "Multiply 2 and 3"}

# Thread
thread = {"configurable": {"thread_id": "1"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('assistant',)
</code></pre></div></div>

<p>이제 상태 업데이트를 직접 적용할 수 있습니다.</p>

<p>메시지 키에 대한 업데이트는 add_messages 리듀서를 사용할 수 있습니다.</p>

<ul>
  <li>기존 메시지를 덮어쓰려면 메시지 ID를 제공하면 됩니다.</li>
  <li>단순히 메시지 목록에 추가하려는 경우 아래와 같이 ID를 지정하지 않고 메시지를 전달할 수 있습니다.</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.update_state(
    thread,
    {"messages": [HumanMessage(content="No, actually multiply 3 and 3!")]},
)
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
================================ Human Message =================================

Multiply 2 and 3
('assistant',)
{'configurable': {'thread_id': '1',
  'checkpoint_ns': '',
  'checkpoint_id': '1eff2610-691e-624f-8001-9d5f35e0e8e0'}}
</code></pre></div></div>

<p>한 번 살펴봅시다.</p>

<p>update_state를 호출하여 새메세지로 업데이트하였습니다.</p>

<p>add_messages 리듀서는 이를 상태 키인 메시지에 추가합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>new_state = graph.get_state(thread).values
for m in new_state['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
================================ Human Message =================================

No, actually multiply 3 and 3!
</code></pre></div></div>

<p>이제 에이전트에 None을 전달하고 현재 상태에서 진행하도록 허용하여 진행하겠습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

No, actually multiply 3 and 3!
================================== Ai Message ==================================

[{'type': 'text', 'text': "Okay, let's multiply 3 and 3:"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 3, 'b': 3}, 'id': 'tooluse_a-AWT-oiRv27JR1vq-enDQ'}]
Tool Calls:
  multiply (tooluse_a-AWT-oiRv27JR1vq-enDQ)
 Call ID: tooluse_a-AWT-oiRv27JR1vq-enDQ
  Args:
    a: 3
    b: 3
================================= Tool Message =================================
Name: multiply

9
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('assistant',)
</code></pre></div></div>

<p>이제 중단점이 있는 어시스턴트로 돌아왔습니다.</p>

<p>다시 None을 전달하여 계속 진행하면 됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================= Tool Message =================================
Name: multiply

9
================================== Ai Message ==================================

The result of multiplying 3 and 3 is 9.
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>()
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[Human in the Loop 변경을 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(6)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(6)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(6)" /><published>2025-05-26T15:06:00+00:00</published><updated>2025-05-26T15:06:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(6)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(6)/"><![CDATA[<h2 id="human-in-the-loop">Human in the Loop</h2>

<p>이제 휴먼 인 더 루프가 필요한 배경에 대해 이야기해 보겠습니다:</p>

<p>(1) 승인 - 에이전트를 중단하고 사용자에게 상태를 표시하고 사용자가 작업을 수락하도록 허용할 수 있습니다.</p>

<p>(2) 디버깅 - 그래프를 되감아 문제를 재현하거나 피할 수 있습니다.</p>

<p>(3) 편집 - 상태를 수정할 수 있습니다.</p>

<p>LangGraph는 다양한 휴먼 인 더 루프 워크플로우를 지원하기 위해 에이전트 상태를 가져오거나 업데이트하는 여러 가지 방법을 제공합니다.</p>

<p>먼저 특정 단계에서 그래프를 멈추는 간단한 방법을 제공하는 <code class="language-plaintext highlighter-rouge">breakpoints</code>를 소개하겠습니다.</p>

<p>이를 통해 어떻게 사용자 승인을 지원하는지 보여드리겠습니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

</code></pre></div></div>

<h2 id="human-승인을-위한-breakpoint">Human 승인을 위한 breakpoint</h2>
<p>이전 모듈에서 작업했던 간단한 에이전트를 다시 생각해 보겠습니다.</p>

<p>에이전트가 도구를 사용할 수 있도록 승인하고 싶다고 가정해 보겠습니다.</p>

<p>여기서 <code class="language-plaintext highlighter-rouge">tools</code> 는 도구 노드입니다. <code class="language-plaintext highlighter-rouge">interrupt_before=["tools"]</code>로 그래프를 컴파일하기만 하면 됩니다.</p>

<p>이렇게 하면, 도구 호출을 실행하는 도구 노드 전에 실행이 중단됩니다.</p>

<h2 id="툴-정의">툴 정의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]
llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<h2 id="그래프-정의">그래프 정의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine the control flow
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")

memory = MemorySaver()
graph = builder.compile(interrupt_before=["tools"], checkpointer=memory)

# Show
display(Image(graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>

<p><img src="/assets/images/post_img/langgraph6.png" alt="langgraph6" /></p>

<h2 id="수행-테스트">수행 테스트</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Input
initial_input = {"messages": HumanMessage(content="Multiply 2 and 3")}

# Thread
thread = {"configurable": {"thread_id": "1"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_4-zyUmE8QkyCpyZdpa60FA'}]
Tool Calls:
  multiply (tooluse_4-zyUmE8QkyCpyZdpa60FA)
 Call ID: tooluse_4-zyUmE8QkyCpyZdpa60FA
  Args:
    a: 2
    b: 3
</code></pre></div></div>

<p>상태를 확인하고 다음 호출할 노드를 확인할 수 있습니다.
그래프가 중단된 것을 확인할 수 있는 좋은 방법입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>state = graph.get_state(thread)
state.next
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('tools',)
</code></pre></div></div>
<p>이제 멋진 트릭을 소개하겠습니다.
<code class="language-plaintext highlighter-rouge">None</code>으로 그래프를 호출하면 마지막 상태 체크포인트부터 계속됩니다!</p>

<p>명확히 하기 위해 LangGraph는 도구 호출과 함께 <code class="language-plaintext highlighter-rouge">AIMessage</code>가 포함된 현재 상태를 다시 전송합니다.</p>

<p>그런 다음 그래프에서 도구 노드부터 시작되는 다음 단계를 실행합니다.</p>

<p>이 도구 호출로 도구 노드가 실행되고 최종 답변을 위해 채팅 모델에 다시 전달되는 것을 볼 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_4-zyUmE8QkyCpyZdpa60FA'}]
Tool Calls:
  multiply (tooluse_4-zyUmE8QkyCpyZdpa60FA)
 Call ID: tooluse_4-zyUmE8QkyCpyZdpa60FA
  Args:
    a: 2
    b: 3
================================= Tool Message =================================
Name: multiply

6
================================== Ai Message ==================================

The result of multiplying 2 and 3 is 6.
</code></pre></div></div>

<p>이제 이를 사용자 입력을 수락하는 구체적인 사용자 승인 단계와 결합해 보겠습니다.</p>

<h2 id="사용자-승인">사용자 승인</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Input
initial_input = {"messages": HumanMessage(content="Multiply 2 and 3")}

# Thread
thread = {"configurable": {"thread_id": "2"}}

# Run the graph until the first interruption
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()

# Get user feedback
user_approval = input("Do you want to call the tool? (yes/no): ")

# Check approval
if user_approval.lower() == "yes":
    
    # If approved, continue the graph execution
    for event in graph.stream(None, thread, stream_mode="values"):
        event['messages'][-1].pretty_print()
        
else:
    print("Operation cancelled by user.")
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply 2 and 3
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_-sDfPvjsQYyb_oGcepgxbA'}]
Tool Calls:
  multiply (tooluse_-sDfPvjsQYyb_oGcepgxbA)
 Call ID: tooluse_-sDfPvjsQYyb_oGcepgxbA
  Args:
    a: 2
    b: 3
Do you want to call the tool? (yes/no):  yes
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 2, 'b': 3}, 'id': 'tooluse_-sDfPvjsQYyb_oGcepgxbA'}]
Tool Calls:
  multiply (tooluse_-sDfPvjsQYyb_oGcepgxbA)
 Call ID: tooluse_-sDfPvjsQYyb_oGcepgxbA
  Args:
    a: 2
    b: 3
================================= Tool Message =================================
Name: multiply

6
================================== Ai Message ==================================

The result of multiplying 2 and 3 is 6..
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[휴먼 인 더 루프를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(5)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(5)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(5)" /><published>2025-05-26T15:05:00+00:00</published><updated>2025-05-26T15:05:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(5)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(5)/"><![CDATA[<h2 id="상태-스키마">상태 스키마</h2>

<p>이 모듈에서는 상태를 저장하는 스키마와 이와 연관된 메모리에 대해서 좀 더 알아보겠습니다.</p>

<h2 id="bedrock-setting">Bedrock Setting</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>
<h2 id="스키마">스키마</h2>

<p>LangGraph에서 <code class="language-plaintext highlighter-rouge">StateGraph</code>를 정의할 때, 우리는 상태스키마를 사용합니다.</p>

<p>상태 스키마는 그래프가 사용하는 데이터를 저장하기 위한 데이터 구조와 데이터 타입을 말합니다.</p>

<p>그래프를 초기 선언할 때, 정의하면, 모든 노드들이 이 상태 스키마를 이용해서 커뮤니케이션합니다.</p>

<p>LangGraph에는 이 상태스키마를 정의해서 사용할 때, 유연한 구성 옵션들을 제공합니다. 그래서 다양한 Python 타입들을 수용하고, 다양한 접근 방법들을 제공합니다.</p>

<h2 id="typeddict">TypedDict</h2>

<p>상태스키마에서 기본적으로 사용하는 클래스 타입은 <code class="language-plaintext highlighter-rouge">TypedDict</code> 입니다.</p>

<p>이 클래스타입은, key를 명시하고, 그에 해당하는 값을 지정하는 것을 지원합니다.</p>

<p>하지만, 엄격하게 데이터타입을 규정해야 하는 업무에서는 <code class="language-plaintext highlighter-rouge">TypedDict</code> 기능 만으로는 부족합니다.</p>

<p>아래는 TypedDict의 예시입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from typing_extensions import TypedDict

class TypedDictState(TypedDict):
    foo: str
    bar: str
</code></pre></div></div>
<p>좀더 명확하게 데이터타입을 규정해서 해당 타입을 사용해야한다라고 하면, <code class="language-plaintext highlighter-rouge">Literal</code> 타입을 쓸 수 있습니다.</p>

<p>아래 예시에서 볼 수 있듯이, <code class="language-plaintext highlighter-rouge">mood</code>는 “happy”나 “sad”만 될 수 있습니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from typing import Literal

class TypedDictState(TypedDict):
    name: str
    mood: Literal["happy","sad"]
</code></pre></div></div>
<p>랭그래프에서 <code class="language-plaintext highlighter-rouge">StateGraph</code>를 입력하여, 우리는 사전정의된 상태 클래스를 사용할 수 있습니다.</p>

<p>그리고, 우리는 각 상태키는 전체 그래프의 커뮤니케이션에서 “채널” 역할로 수행하게 할 수 있습니다.</p>

<p>우리는 각 노드에서 상태그래프에 있는 상태키를 바꿀 수 있습니다.</p>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import random
from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END

def node_1(state):
    print("---Node 1---")
    return {"name": state['name'] + " is ... "}

def node_2(state):
    print("---Node 2---")
    return {"mood": "happy"}

def node_3(state):
    print("---Node 3---")
    return {"mood": "sad"}

def decide_mood(state) -&gt; Literal["node_2", "node_3"]:
        
    # Here, let's just do a 50 / 50 split between nodes 2, 3
    if random.random() &lt; 0.5:

        # 50% of the time, we return Node 2
        return "node_2"
    
    # 50% of the time, we return Node 3
    return "node_3"

# Build graph
builder = StateGraph(TypedDictState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph5.png" alt="langgraph5" /></p>

<p>스테이트는 딕셔너리이므로 딕셔너리로 그래프를 호출하여 스테이트의 <code class="language-plaintext highlighter-rouge">name</code> 키의 초기 값을 설정하기만 하면 됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke({"name":"Lance"})
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 3---
{'name': 'Lance is ... ', 'mood': 'sad'}
</code></pre></div></div>

<h2 id="dataclass">Dataclass</h2>

<p>파이썬의 데이터클래스는 구조화된 데이터를 정의하는 또 다른 방법을 제공합니다.</p>

<p>데이터클래스는 주로 데이터를 저장하는 데 사용되는 클래스를 생성하기 위한 간결한 구문을 제공합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from dataclasses import dataclass

@dataclass
class DataclassState:
    name: str
    mood: Literal["happy","sad"]
</code></pre></div></div>
<p>데이터클래스의 키에 액세스하려면 node_1에서 사용된 상태스키마를 수정하기만 하면 됩니다:</p>

<p>데이터 클래스 상태에는 위의 TypedDict에 state[“name”]이 아닌 state.name을 사용합니다.</p>

<p>LangGraph가 상태 객체의 각 키를 개별적으로 저장합니다.</p>

<p>노드가 반환하는 객체에는 상태의 키(속성)와 일치하는 키만 있으면 됩니다!</p>

<p>이 경우 데이터클래스에 키 이름이 있으므로 state가 TypedDict일 때와 마찬가지로 노드에서 딕셔너리를 전달하여 업데이트할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def node_1(state):
    print("---Node 1---")
    return {"name": state.name + " is ... "}

# Build graph
builder = StateGraph(DataclassState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph5.png" alt="langgraph5" /></p>

<p>데이터클래스로 호출하여 스테이트의 각 키/채널의 초기값을 설정합니다!
아래와 같이 초기값을 설정하여 수행하도록 유도할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke(DataclassState(name="Lance",mood="sad"))
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 3---
{'name': 'Lance is ... ', 'mood': 'sad'}
</code></pre></div></div>

<h2 id="pydantic">Pydantic</h2>

<p>앞서 언급했듯이 TypedDict와 데이터클래스는 타입 힌트를 제공하지만 런타임에 타입을 강제하지는 않습니다.</p>

<p>즉, 오류를 발생시키지 않고 잘못된 값을 할당할 수 있습니다!</p>

<p>예를 들어, 유형 힌트에 무드가 지정되어 있어도 무드를 mad로 설정할 수 있습니다: <code class="language-plaintext highlighter-rouge">mood: list[Literal["happy","sad"]]</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataclass_instance = DataclassState(name="Lance", mood="mad")
</code></pre></div></div>

<p>Pydantic은 Python 유형 주석을 사용하는 데이터 유효성 검사 및 설정 관리 라이브러리입니다.</p>

<p>유효성 검사 기능으로 인해 LangGraph에서 상태 스키마를 정의하는 데 특히 적합합니다.</p>

<p>Pydantic은 유효성 검사를 수행하여 런타임에 데이터가 지정된 유형과 제약 조건을 준수하는지 확인할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from pydantic import BaseModel, field_validator, ValidationError

class PydanticState(BaseModel):
    name: str
    mood: str # "happy" or "sad" 

    @field_validator('mood')
    @classmethod
    def validate_mood(cls, value):
        # Ensure the mood is either "happy" or "sad"
        if value not in ["happy", "sad"]:
            raise ValueError("Each mood must be either 'happy' or 'sad'")
        return value

try:
    state = PydanticState(name="John Doe", mood="mad")
except ValidationError as e:
    print("Validation Error:", e)
</code></pre></div></div>

<p>이런 Pydantic의 기능을 이용해서 그래프에서 PydanticState를 원활하게 사용할 수 있습니다.</p>

<h2 id="그래프-생성-1">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Build graph
builder = StateGraph(PydanticState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph5.png" alt="langgraph5" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke(PydanticState(name="Lance",mood="sad"))
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 2---
{'name': 'Lance is ... ', 'mood': 'happy'}
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[상태 스키마를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(4)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(4)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(4)" /><published>2025-05-26T15:04:00+00:00</published><updated>2025-05-26T15:04:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(4)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(4)/"><![CDATA[<h2 id="그래프-메모리란">그래프 메모리란?</h2>
<p>Agent를 통해서 처리되는 것들을 살펴 보았습니다.
하지만, LLM은 기본적으로 사용자가 수행하는 대화를 기억하지 못합니다.
그래서 그래프에서도 사용자가 수행하는 대화를 기억할 수 있도록 하는 장치가 필요합니다.
그래서 그래프 메모리는 이렇게 사용자가 수행한 대화를 기억할 수 있도록 도와서 컨텍스트에 맞는 답변을 하도록 도움을 줍니다.</p>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")
</code></pre></div></div>
<h2 id="툴-생성">툴 생성</h2>
<p>이전 실습과 동일하게 아래와 같은 툴들을 생성합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Divide a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]
llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<h2 id="assistant-함수-정의">Assistant 함수 정의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import MessagesState
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode
from IPython.display import Image, display

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine how the control flow moves
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")
react_graph = builder.compile()

# Show
display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph4.png" alt="langgraph4" /></p>

<h1 id="메모리-관련-수행-테스트">메모리 관련 수행 테스트</h1>

<p>생성된 그래프 에이전트를 아래와 같이 수행합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Add 3 and 4.")]
messages = react_graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_H7NSwbEZTly89MQ_60KYfg'}]
Tool Calls:
  add (tooluse_H7NSwbEZTly89MQ_60KYfg)
 Call ID: tooluse_H7NSwbEZTly89MQ_60KYfg
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

The result of adding 3 and 4 is 7.
</code></pre></div></div>

<h2 id="메모리-없이-수행-테스트테스트">메모리 없이 수행 테스트테스트</h2>
<p>이 상태에서 앞의 결과를 참조해서 아래와 같이 질문합니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Multiply that by 2.")]
messages = react_graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Multiply that by 2.
================================== Ai Message ==================================

[{'type': 'text', 'text': "Okay, let's multiply the previous result by 2."}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': '$PREVIOUS_RESULT', 'b': 2}, 'id': 'tooluse_P1TkD006QBSvvAITldWUyg'}]
Tool Calls:
  multiply (tooluse_P1TkD006QBSvvAITldWUyg)
 Call ID: tooluse_P1TkD006QBSvvAITldWUyg
  Args:
    a: $PREVIOUS_RESULT
    b: 2
================================= Tool Message =================================
Name: multiply

Error: 1 validation error for multiply
a
  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='$PREVIOUS_RESULT', input_type=str]
    For further information visit https://errors.pydantic.dev/2.9/v/int_parsing
 Please fix your mistakes.
================================== Ai Message ==================================

Oops, it looks like I don't have a previous result stored. Could you please provide the number you would like me to multiply by 2?
</code></pre></div></div>

<h2 id="메모리를-활용한-수행-테스트">메모리를 활용한 수행 테스트</h2>
<p>에이전트는 이전 결과값을 알 지 못해서 위의 결과와 같이 계산을 할 수 없다고 답변합니다.</p>

<p>그 이유는 LLM은 사용자의 대화를 기억하지 못하기 때문입니다.</p>

<p>그래서, 이런 방식으로 그대로 수행하게 되면, 멀티턴을 이용하는 대화방식을 구현이 쉽지 않습니다.</p>

<p>그래서, 여기에서 우리는 <code class="language-plaintext highlighter-rouge">persistence</code> 아키텍처를 이용할 수 있습니다.</p>

<p>LangGraph에서는 <code class="language-plaintext highlighter-rouge">checkpointer</code>라는 개념을 이용해서, 그래프의 상태를 저장하도록 할 수 있습니다.</p>

<p>LangGraph에서 자체 지원하는 persistence 레이어는 memory로 구성하는 것을 지원합니다. 이를 통해서 마지막 대화나, 진행 상태에 대해서 정보를 참조할 수 있습니다.</p>

<p>가장 쉽게 구현할 수 있는 <code class="language-plaintext highlighter-rouge">Checkpointer</code>는 <code class="language-plaintext highlighter-rouge">MemorySaver</code>입니다. <code class="language-plaintext highlighter-rouge">MemorySaver</code>는 그래프 상태를 저장할 수 있는 key-value 스토업니다.</p>

<p>이를 구현하는 방법은 간단합니다.
그래프르 컴파일할 때, checkpointer 아규먼트와 함께 컴파일하면 됩니다. 그러면, 그래프는 메모리를 갖게 됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.checkpoint.memory import MemorySaver
memory = MemorySaver()
react_graph_memory = builder.compile(checkpointer=memory)
</code></pre></div></div>

<p>실제로 대화가 이루어질 때는 어려사용자들이 동시에 사용하게 됩니다.
그래서 사용자는 세션을 구분하기위한 장치가 필요합니다.
그래서, 그래프에서 메모리를 사용할 때는 <code class="language-plaintext highlighter-rouge">thread_id</code> 아규먼트를 이용해서 세션을 구분하도록 합니다.</p>

<p>This <code class="language-plaintext highlighter-rouge">thread_id</code> will store our collection of graph states.
이 <code class="language-plaintext highlighter-rouge">thread_id</code>를 통해서 그래프 상태를 저장할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Specify a thread
config = {"configurable": {"thread_id": "1"}}

# Specify an input
messages = [HumanMessage(content="Add 3 and 4.")]

# Run
messages = react_graph_memory.invoke({"messages": messages},config)
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_p4Z-a9woSemlo7TWzNaH5Q'}]
Tool Calls:
  add (tooluse_p4Z-a9woSemlo7TWzNaH5Q)
 Call ID: tooluse_p4Z-a9woSemlo7TWzNaH5Q
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

The result of adding 3 and 4 is 7.
</code></pre></div></div>
<p>위에서 수행한 결과에 대해서 <code class="language-plaintext highlighter-rouge">thread_id</code>를 통해서 메모리 처리가 잘 되는지를 확인해 볼 수 있습니다.
<code class="language-plaintext highlighter-rouge">thread_id</code>를 통해서 이전에 수행한 결과를 참조해 볼 수 있습니다.</p>

<p>이 예시에서 볼 수 있듯이, 이전에 수행한 대화를 참조할 수 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">HumanMessage</code>에 <code class="language-plaintext highlighter-rouge">"Multiply that by 2."</code>라는 메세지를 수행하면, 이전 대화의 내용에 append 되어 저장됩니다.</p>

<p>그래서 이제 모델은 <code class="language-plaintext highlighter-rouge">that</code>이라는 지시어가 이전에 문의한 질문에 대한 답변인 <code class="language-plaintext highlighter-rouge">The sum of 3 and 4 is 7.</code> 임을 알게됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Multiply that by 2.")]
messages = react_graph_memory.invoke({"messages": messages}, config)
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_p4Z-a9woSemlo7TWzNaH5Q'}]
Tool Calls:
  add (tooluse_p4Z-a9woSemlo7TWzNaH5Q)
 Call ID: tooluse_p4Z-a9woSemlo7TWzNaH5Q
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

The result of adding 3 and 4 is 7.
================================ Human Message =================================

Multiply that by 2.
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 7, 'b': 2}, 'id': 'tooluse_QPBCvXWOQwGLCH4mudVp7Q'}]
...
14
================================== Ai Message ==================================

The result of multiplying 7 by 2 is 14.
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[그래프 메모리를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(3)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(3)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(3)" /><published>2025-05-26T15:03:00+00:00</published><updated>2025-05-26T15:03:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(3)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(3)/"><![CDATA[<h2 id="툴-에이전트-실습">툴 에이전트 실습</h2>

<p>앞에서 라우터를 실습해 봤기 때문에, 여기에서는 좀 더 해당 개념을 확장해서 수행할 예정입니다.</p>

<p>우리는 앞의 라우터 실습에서, LLM에게 질의를 하였고, 만약에 질의의 내용이 툴을 호출하는 것이라면, <code class="language-plaintext highlighter-rouge">ToolMessage</code>를 통해서 답변을 하는 것을 보았습니다.</p>

<p>이번에는, ToolMessage를 바로 사용자에게 답변하는 것이 아니라, 이 메세지를 다시 모델에게 전달할 수 있을까요?</p>

<p>그래서 이번에는 툴을 통해서 나온 답변을 이용해서 또 다른 툴에게 인풋으로 사용하라고 전달하거나, 바로 사용자에게 답변이 가능한지를 실험해 보도록 하겠습니다.</p>

<p>이러한 접근 방식이 기본적인 ReAct에서 수행하는 접근법과 동일한 접근법입니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">act</code> - 모델이 툴을 사용합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">observe</code> - 툴의 결과값을 다시 모델에게 전달합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">reason</code> - 툴의 결과값에 대해서 다른 툴을 호출해야 되는지 등에 대한 reasoning을 수행합니다.</li>
</ul>

<p>이 접근법은 다양한 Agent 아키텍처에서 공통으로 활용될 수 있습니다.</p>

<h2 id="bedrock-setup">Bedrock Setup</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import getpass
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

</code></pre></div></div>

<h2 id="여러개의-툴들을-정의">여러개의 툴들을 정의</h2>

<p>아래와 같이, 덧셈, 곱셈, 나눗셈 툴을 정의합니다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

# This will be a tool
def add(a: int, b: int) -&gt; int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -&gt; float:
    """Divide a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]

llm_with_tools = llm.bind_tools(tools)
</code></pre></div></div>

<p>LLM assitant를 만들어서 전체적인 agent 동작을 관장하도록 합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, SystemMessage

# System message
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# Node
def assistant(state: MessagesState):
   return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}
</code></pre></div></div>

<p>이전에는 <code class="language-plaintext highlighter-rouge">Tools</code> 노드를 생성해서 이 노드에서 툴들을 처리하도록 하였습니다.</p>

<p>이번에는 <code class="language-plaintext highlighter-rouge">Assistant</code> 노드를 만들었고, 이 노드에서 LLM이 명시적으로 동작하도록 세팅하고 있습니다.</p>

<p>마찬가지로 <code class="language-plaintext highlighter-rouge">Assistant</code>와 <code class="language-plaintext highlighter-rouge">Tools</code> 노드를 생성합니다.</p>

<p>그리고 <code class="language-plaintext highlighter-rouge">tools_condition</code> 엣지르를 구성합니다. 이 엣지는 입력되는 요건에 따라서 툴을 사용하게 할 것인지, 바로 답변을 수행해서 <code class="language-plaintext highlighter-rouge">End</code> 노드로 분기하도록 할지를 결정합니다.</p>

<p>그리고 한가지 단계가 더 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">Tools</code>에 대한 답변을 다시 <code class="language-plaintext highlighter-rouge">Assistant</code>노드로 전달하도록 루프를 생성합니다. 이 루프는 아래와 같은 방식으로 동작합니다.</p>

<ul>
  <li>최초에 <code class="language-plaintext highlighter-rouge">assistant</code> 노드가 수행된 이후에, <code class="language-plaintext highlighter-rouge">tools_condition</code>이 툴을 수행할 것인지를 결정합니다.</li>
  <li>Tool call이 결정된다면, <code class="language-plaintext highlighter-rouge">tools</code>노드가 수행되도록 분기합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">tools</code>의 수행결과는 다시 <code class="language-plaintext highlighter-rouge">assistant</code>노드로 되돌아갑니다.</li>
  <li>이 루프는 <code class="language-plaintext highlighter-rouge">assistant</code> 노드에서 툴 호출이 계속적으로 필요하다고 판단된다면, 계속적으로 수행합니다.</li>
  <li>모델의 결과가 툴 호출이 더 이상 필요하지 않다고 판단된다면, 플로우는 END노드로 넘어갑니다. 이로서 모든 수행이 끝납니다.</li>
</ul>

<h2 id="그래프-생성">그래프 생성</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langgraph.prebuilt import ToolNode
from IPython.display import Image, display

# Graph
builder = StateGraph(MessagesState)

# Define nodes: these do the work
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# Define edges: these determine how the control flow moves
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", "assistant")
react_graph = builder.compile()

# Show
display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph3.png" alt="langgraph3" /></p>

<h2 id="그래프-수행-테스트">그래프 수행 테스트</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="Add 3 and 4. Multiply the output by 2. Divide the output by 5")]
messages = react_graph.invoke({"messages": messages})
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

Add 3 and 4. Multiply the output by 2. Divide the output by 5
================================== Ai Message ==================================

[{'type': 'text', 'text': "Okay, let's do that step-by-step:"}, {'type': 'tool_use', 'name': 'add', 'input': {'a': 3, 'b': 4}, 'id': 'tooluse_u8LY5iziQtu7L-LLq_AlRw'}]
Tool Calls:
  add (tooluse_u8LY5iziQtu7L-LLq_AlRw)
 Call ID: tooluse_u8LY5iziQtu7L-LLq_AlRw
  Args:
    a: 3
    b: 4
================================= Tool Message =================================
Name: add

7
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 7, 'b': 2}, 'id': 'tooluse_gxPpRu89TfWwIfjF2fQAQw'}]
Tool Calls:
  multiply (tooluse_gxPpRu89TfWwIfjF2fQAQw)
 Call ID: tooluse_gxPpRu89TfWwIfjF2fQAQw
  Args:
    a: 7
    b: 2
...
2.8
================================== Ai Message ==================================

So the final result is 2.8.
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[툴 에이전트를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(2)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(2)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(2)" /><published>2025-05-26T15:02:00+00:00</published><updated>2025-05-26T15:02:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(2)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(2)/"><![CDATA[<h2 id="라우터란">라우터란?</h2>

<p>사용자의 인풋에 따라서, Gen AI를 컨텍스트에 맞는 답변을 수행해야 하는지를 판단하게 할 수 있습니다.
이러한 작업을 수행하는 것이 라우터입니다.
그래서 사용자의 컨텍스트에 맞게 해당되는 툴로 답변을 유도하거나, LLM이 스스로 답변하는 형태로 답변하도록 합니다.</p>

<p>이 실습예제도 사용자의 요청에 따라서 툴을 사용하거난, LLM을 통해서 직접 답변하게는 등의 수행이 제대로 되는지를 실습해 볼 예정입니다.</p>

<p>이러한 라우터 방식이 동작하게 하기 위해서 아래의 2가지 형태를 준비할 예정입니다.</p>
<ul>
  <li>우선 툴을 사용하는 노드를 구성합니다.</li>
  <li>그리고 조건부 엣지를 생성합니다. 이 조건부 엣지에서는 사용자 인풋에 따라서, 툴을 사용하게 할 것인지, LLM이 직접 답변하게 할 지 등에 대해서 라우터 역할을 수행하게 할 것입니다.</li>
</ul>

<h2 id="bedrock-setup">Bedrock setup</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import boto3
from langchain_aws import ChatBedrockConverse
from langchain_aws import ChatBedrock

# ---- ⚠️ Update region for your AWS setup ⚠️ ----
aws_region = os.getenv("AWS_REGION")
bedrock_client = boto3.client("bedrock-runtime", region_name=aws_region)

llm = ChatBedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    temperature=0,
    max_tokens=None,
    client=bedrock_client,
    # other params...
)

llm.invoke("what is the Amazon Nova?")

</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AIMessage(content="The Amazon Nova is a line of tablet computers developed and sold by Amazon. Some key details about the Amazon Nova tablets:\n\n- They are part of Amazon's Fire tablet lineup, which also includes the standard Fire tablets and the Fire HD tablets.\n\n- The Amazon Nova tablets are designed to be more premium and higher-end models compared to the standard Fire tablets.\n\n- They typically feature larger screen sizes, more powerful processors, more RAM, and additional storage compared to the base Fire tablets.\n\n- The Amazon Nova tablets run Amazon's Fire OS, which is a customized version of the Android operating system.\n\n- They are primarily designed to integrate with Amazon's ecosystem of services like Amazon Prime, Kindle, Alexa, and Amazon's digital content stores.\n\n- Some recent models in the Amazon Nova line include the Fire HD 10 Plus and the Fire HD 10 Productivity Edition, which are positioned as more advanced and capable tablets.\n\nSo in summary, the Amazon Nova represents Amazon's higher-end tablet offerings that sit above their standard Fire tablet models in terms of features and performance.", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'b2d2e840-07b8-4970-ab9e-d071784071dc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 27 Feb 2025 03:19:58 GMT', 'content-type': 'application/json', 'content-length': '1306', 'connection': 'keep-alive', 'x-amzn-requestid': 'b2d2e840-07b8-4970-ab9e-d071784071dc'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': 2564}}, id='run-1c7d4c35-2075-4e2d-b882-3f38ff843b09-0', usage_metadata={'input_tokens': 13, 'output_tokens': 228, 'total_tokens': 241})
</code></pre></div></div>

<h2 id="툴-함수-생성">툴 함수 생성</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def multiply(a: int, b: int) -&gt; int:
    """This tool is to multiply two input argrments such as a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

llm_with_tools = llm.bind_tools([multiply])
</code></pre></div></div>

<h2 id="그래프-생성">그래프 생성</h2>

<p>우리는 아주 쉽고 간단한 형태로 구현하는 것을 수행해 볼 것입니다.
LangGraph에서 제공하는 <code class="language-plaintext highlighter-rouge">ToolNode</code> 패키지를 이용할 것입니다.
툴노드를 사용하게 되면, 간단하게 생성된 툴들을 이 노드에서 처리하도록 할 수 있습니다.</p>

<p>그리고 Langgraph에서 제공하는 <code class="language-plaintext highlighter-rouge">tools_condition</code>을 조건부 엣지에서 사용할 예정입니다.
이 기능을 사용하게 되면, 사용자의 입력에 따라서 자동으로 어떤 툴들을 사용할지에 대해서 분기합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END
from langgraph.graph import MessagesState
from langgraph.prebuilt import ToolNode
from langgraph.prebuilt import tools_condition

# Node
def tool_calling_llm(state: MessagesState):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

# Build graph
builder = StateGraph(MessagesState)
builder.add_node("tool_calling_llm", tool_calling_llm)
builder.add_node("tools", ToolNode([multiply]))
builder.add_edge(START, "tool_calling_llm")
builder.add_conditional_edges(
    "tool_calling_llm",
    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools
    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END
    tools_condition,
)
builder.add_edge("tools", END)
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph2.png" alt="langgraph2" /></p>

<h2 id="일상적인-대화로-질의">일상적인 대화로 질의</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_core.messages import HumanMessage
messages = [HumanMessage(content="안녕 잘 지내?")]
messages = graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

안녕 잘 지내?
================================== Ai Message ==================================

네, 저도 잘 지내고 있습니다. 오늘 날씨가 좋아서 기분이 좋네요. 어떤 계획이 있으신가요? 함께 즐거운 시간을 보내면 좋겠습니다.
</code></pre></div></div>

<h2 id="곱셈을-문의하는-질의">곱셈을 문의하는 질의</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>messages = [HumanMessage(content="134 곱하기 1435를 계산하면 얼마야?")]
messages = graph.invoke({"messages": messages})
for m in messages['messages']:
    m.pretty_print()
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================ Human Message =================================

134 곱하기 1435를 계산하면 얼마야?
================================== Ai Message ==================================

[{'type': 'tool_use', 'name': 'multiply', 'input': {'a': 134, 'b': 1435}, 'id': 'tooluse_FYpRmFUlTz6BQRNDuX6Fpg'}]
Tool Calls:
  multiply (tooluse_FYpRmFUlTz6BQRNDuX6Fpg)
 Call ID: tooluse_FYpRmFUlTz6BQRNDuX6Fpg
  Args:
    a: 134
    b: 1435
================================= Tool Message =================================
Name: multiply

192290
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[라우터를 알아보자]]></summary></entry><entry><title type="html">Agentic_Workflow_using_LangGraph_and_Bedrock(1)</title><link href="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(1)/" rel="alternate" type="text/html" title="Agentic_Workflow_using_LangGraph_and_Bedrock(1)" /><published>2025-05-26T15:01:00+00:00</published><updated>2025-05-26T15:01:00+00:00</updated><id>https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(1)</id><content type="html" xml:base="https://aidendef.github.io//ai/cloud/Agentic_Workflow_using_LangGraph_and_Bedrock(1)/"><![CDATA[<h2 id="간단한-그래프">간단한 그래프</h2>

<p>LangGraph에서 개념을 갖고 있는 Graph에 대해서 알아보기 위해서, 아주 간단한 그래프를 그려볼 것입니다.
간단한 3개의 노드를 이용해서 그래프를 그려볼 수 있습니다.</p>

<h2 id="패키지-설치">패키지 설치</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%%capture --no-stderr
%pip install --quiet -U langgraph
</code></pre></div></div>

<h2 id="state-상태저장">State (상태저장)</h2>

<p>우선, 그래프의 상태를 저장하는 State class를 우선 정의합니다.
이 상태 스키마는 그래프의 모든 노드에 대한 정보들을 저장하고 처리합니다.</p>

<p>정형화된 데이터 저장을 위해서, 이번 예시에서는 <code class="language-plaintext highlighter-rouge">TypedDict</code> 클래스를 이용해서 State를 생성합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from typing_extensions import TypedDict

class State(TypedDict):
    graph_state: str
</code></pre></div></div>

<h2 id="노드">노드</h2>

<p>그래프에서 각각이 의미있는 수행포인트를 지정하는 것이 노드입니다.</p>

<p>각각의 노드들은 그래프의 현재 상태를 알고 판단을 수행해야 하기 때문에, 위에서 정의한 state 클래스를 입력 아규먼트로 사용합니다.</p>

<p>위에서 State를 정의할 때, graph_state에 대한 멤버변수를 정의했기 때문에, 각 노드에서는 state 클래스의 멤버변수를 접근하여 활용할 수 있습니다.</p>

<p>그리고 각 노드는 처리된 결과를 리턴합니다.</p>

<p>이 예제에서는 각 노드에서 이전 state에 저장된 정보를 계속해서 업데이트하면서 결과가 어떻게 바뀌는지를 확인할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def node_1(state):
    print("---Node 1---")
    return {"graph_state": state['graph_state'] +" I am"}

def node_2(state):
    print("---Node 2---")
    return {"graph_state": state['graph_state'] +" happy!"}

def node_3(state):
    print("---Node 3---")
    return {"graph_state": state['graph_state'] +" sad!"}
</code></pre></div></div>

<h2 id="엣지">엣지</h2>

<p>노드가 각 역할을 수행하는 점들이라고 한다면, 엣지를 각 점들을 연결하는 역할을 수행합니다.</p>

<p>이 방식을 통해서, 각 노드들을 연결하면서, 전체적인 Workflow 그래프를 완성합니다.</p>

<p>기본적인 엣지의 형태는 노드1에서 노드2로 연결하는 역할만 수행합니다.</p>

<p>조건분기 엣지는 입력되는 결과에 따라서 다음에 수행해야 하는 노드를 선택하는 조건을 분기하는 로직을 넣어서 처리하는 역할을 수행합니다. 그래서 분기할 수 있는 로직을 넣어서 처리합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import random
from typing import Literal

def decide_mood(state) -&gt; Literal["node_2", "node_3"]:
    
    # Often, we will use state to decide on the next node to visit
    user_input = state['graph_state'] 
    
    # Here, let's just do a 50 / 50 split between nodes 2, 3
    if random.random() &lt; 0.5:

        # 50% of the time, we return Node 2
        return "node_2"
    
    # 50% of the time, we return Node 3
    return "node_3"
</code></pre></div></div>

<h2 id="그래프-구성">그래프 구성</h2>

<p>이전 과정까지, 노드와 엣지에 대해서 설명했으니, 그래프를 이제 그릴 수 있습니다.</p>

<p>우선, StateGraph를 초기화하여 생성합니다.</p>

<p>그리고, 노드와 엣지를 추가합니다.</p>

<p>그래프를 시작할 때는 <code class="language-plaintext highlighter-rouge">START</code>라는 특수 노드를 우선 정의해야 합니다.
이 노드이 있어야 그래프가 시작할 수 있습니다.</p>

<p>마찬가지로, <code class="language-plaintext highlighter-rouge">END</code>라는 특수 노드를 정의해야 합니다.
이 노드를 통해서 그래프의 최종 상태를 정의할 수 있습니다.</p>

<p>마지막으로 이렇게 정의된 내용들을 <code class="language-plaintext highlighter-rouge">compile</code>하면 그래프가 완성됩니다.</p>

<p>그리고 이렇게 만들어진 그래프를 Mermain diagram 기능을 이용해서 그래프를 png 파일로 visualize 할 수 있습니다.
이렇게 Visualization 방식을 통해서 그래프를 빠르게 이해할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def dummy_func(state) -&gt; Literal["node_2", "node_3"]:
    
    # Often, we will use state to decide on the next node to visit
    user_input = state['graph_state']

    return "node_2"
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END

# Build graph
builder = StateGraph(State)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", dummy_func)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>
<p><img src="/assets/images/post_img/langgraph1.png" alt="langgraph1" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from IPython.display import Image, display
from langgraph.graph import StateGraph, START, END


# Build graph
builder = StateGraph(State)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)

# Logic
builder.add_edge(START, "node_1")
builder.add_conditional_edges("node_1", decide_mood)
builder.add_edge("node_2", END)
builder.add_edge("node_3", END)

# Add
graph = builder.compile()

# View
display(Image(graph.get_graph().draw_mermaid_png()))
</code></pre></div></div>

<h2 id="그래프-호출">그래프 호출</h2>

<p>The compiled graph implements the <a href="https://python.langchain.com/v0.1/docs/expression_language/interface/">runnable</a> protocol.
이렇게 컴파일된 그래프는 LangChain의 <code class="language-plaintext highlighter-rouge">runnable</code>로 동작합니다.</p>

<p>이 방식은 LangChain 콤포넌트들을 효과적으로 처리합니다.</p>

<p><code class="language-plaintext highlighter-rouge">invoke</code>는 이러한 <code class="language-plaintext highlighter-rouge">runnable</code> 동작 아키텍처의 기본적인 호출 방식입니다.</p>

<p>여기에서 처음 수행해 보는 예시는 <code class="language-plaintext highlighter-rouge">{"graph_state": "Hi, this is lance."}</code>형태로 아주 간단한 메세지를 전달하는 것입니다. 그래프의 상태를 dict 형태로 정의했기 때문에, dict 형태의 메세지로 만들어서 호출합니다. 이 메세지를 인풋값으로 초기에 호출합니다.</p>

<p>이 <code class="language-plaintext highlighter-rouge">invoke</code>가 그래프를 통해서 호출되면, 그래프는 <code class="language-plaintext highlighter-rouge">START</code> 노드에서부터 진행을 시작합니다.</p>

<p>그러면 각 노드들은 차례대로 진행합니다.</p>

<p>조건분기 엣지에서는 랜덤 로직을 구현하였습니다. 그래서 노드2와 노드3를 50%의 확률로 번갈아가면서 호출합니다.</p>

<p>각 노드 함수는 현재 상태를 수신하니다. 그리고 처리된 결과를 graph state 클래스에 업데이트합니다.</p>

<p>이 수행은 <code class="language-plaintext highlighter-rouge">END</code>노드에 다달을 때까지 지속합니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>graph.invoke({"graph_state" : "Hi, this is Lance."})
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---Node 1---
---Node 3---
{'graph_state': 'Hi, this is Lance. I am sad!'}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">invoke</code> 는 그래프에서 동기방식으로 동작합니다.</p>

<p>그래서, 이전 단계가 완전히 끝나기를 기다렸다가 수행합니다.</p>

<p>모든 노드의 수행이 끝나면 마지막 graph state 값을 출력합니다.</p>

<p>이 예시에서는 노드2나 노드3이 완전히 끝나고 나서 결과를 출력합니다. 아래와 같은 결과가 출력됩니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'graph_state': 'Hi, this is Lance. I am sad!'}
</code></pre></div></div>]]></content><author><name>Your Name</name></author><category term="ai" /><category term="cloud" /><category term="AWS" /><category term="Agentic" /><category term="LangGraph" /><category term="Bedrock" /><summary type="html"><![CDATA[그래프를 알아보자]]></summary></entry></feed>